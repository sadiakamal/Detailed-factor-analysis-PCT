{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e779bbd2-bfb6-44ca-a2a9-9c21a02b6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import levene\n",
    "from pingouin import welch_anova\n",
    "from rpy2.robjects import pandas2ri, r\n",
    "from rpy2.robjects.packages import importr\n",
    "pandas2ri.activate()\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "ARTool = importr('ARTool')\n",
    "base = importr('base')\n",
    "stats = importr('stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "001353c9-1981-4340-9a9f-bbf009feb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gsheet(url: Optional[str]=None, sheet_id: Optional[str]=None, gid: Optional[str]=None):\n",
    "    if url is not None:\n",
    "        match = re.search(r\"spreadsheets/d/([^/]+)/.*?[?&]gid=(\\d+)\", url)\n",
    "        if match:\n",
    "            sheet_id = match.group(1)\n",
    "            gid = match.group(2)\n",
    "        else:\n",
    "            print(\"can't parse url to get sheet id and gid\")\n",
    "    else:\n",
    "        assert sheet_id is not None and gid is not None, \"Sheet id an gid must be not None when url is not None\"\n",
    "    _url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&id={sheet_id}&gid={gid}\"\n",
    "    return pd.read_csv(_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31fe48a1-cfd5-4050-b311-cb66a24c0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_way_anova(_filter_df: pd.DataFrame, independent_vars: Optional[List[str]] = [\"fine_tune_dataset\"],\n",
    "                    dependent_var: Optional[str] = \"output_x\", collapse: bool=True):\n",
    "    \"\"\"\n",
    "    do multi way anova on the provided dataframe.\n",
    "    :param _filter_df: output from a model\n",
    "    :param dependent_var: predicted variable (column name in the df)\n",
    "    :param independent_vars: contributing factors\n",
    "    :param collapse: instead of saying which dataset it is finetuned on, we will just have 2 values\n",
    "    for this factor -- whether it is finetuned or not\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if collapse:\n",
    "        mapping = {'Base': 'Base'}\n",
    "        _filter_df.loc[:, 'fine_tune_dataset'] = _filter_df['fine_tune_dataset'].map(mapping).fillna('fine_tuned')\n",
    "    # print(f\"df size: {_filter_df.shape}\")\n",
    "    # levene\n",
    "    grouped_data =  _filter_df.groupby(independent_vars)[dependent_var].apply(list)\n",
    "    stat, pval = levene(*grouped_data, center='mean')\n",
    "    print(f\"Levene’s Test: Statistic = {stat:.4f}, p-value = {pval:.4g}\")\n",
    "    if pval < 0.05: # pval must be < 0.05 for us to reject the H_0 at Levenes.\n",
    "        print(\"Robust ANOVA\")\n",
    "        r_df = pandas2ri.py2rpy(_filter_df)\n",
    "        r.assign(\"rdf\", r_df)\n",
    "\n",
    "        for var in independent_vars:\n",
    "            r(f\"rdf${var} <- as.factor(rdf${var})\")\n",
    "        formula_str = f\"{dependent_var} ~ {' * '.join(independent_vars)}\"\n",
    "        r(f'''\n",
    "            library(ARTool)\n",
    "            model <- art({formula_str}, data = rdf)\n",
    "            art_result <- anova(model, type=2)\n",
    "        ''')\n",
    "\n",
    "        art_result = r('art_result')\n",
    "        art_df = pandas2ri.rpy2py(art_result)\n",
    "        return art_df\n",
    "    formula = f\"{dependent_var} ~\" + ' + '.join([f'C({col})' for col in independent_vars])\n",
    "    _model = ols(formula, data=_filter_df).fit()\n",
    "    anova_table = sm.stats.anova_lm(_model, typ=2)\n",
    "    anova_table['eta_sq'] = anova_table['sum_sq'] / anova_table['sum_sq'].sum()\n",
    "    return anova_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23886fa5-bd30-45cf-aa8f-33969b32b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_way_anova(_filter_df: pd.DataFrame, independent_var: Optional[str] = \"fine_tune_dataset\",\n",
    "                  dependent_var: Optional[str] = \"output_x\", collapse: bool=True):\n",
    "    \"\"\"\n",
    "    do one way anova on the provided dataframe.\n",
    "    :param _filter_df: output from a model\n",
    "    :param dependent_var: predicted variable (column name in the df)\n",
    "    :param independent_var: contributing factor\n",
    "    :param collapse: instead of saying which dataset it is finetuned on, we will just have 2 values\n",
    "    for this factor -- whether it is finetuned or not\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #print(f\"df size: {_filter_df.shape}\")\n",
    "    # suppose the independent variable is prompt, then, it is possible that the dependent variable has the same value for all the prompts. \n",
    "    # in that case, we should filter out those rows as the variance will be zero.\n",
    "    grouped_data = _filter_df.groupby(independent_var)\n",
    "    for group_name, group in grouped_data:\n",
    "        if group[dependent_var].nunique() <= 1:\n",
    "            print(f\"Group '{group_name}' has only one unique value for '{dependent_var}', removing it from analysis.\")\n",
    "            _filter_df = _filter_df[_filter_df[independent_var] != group_name]\n",
    "    #print(f\"df size after filtering: {_filter_df.shape}\")\n",
    "    mapping = {'Base': 'Base'}\n",
    "    _filter_df.loc[:, 'fine_tune_dataset'] = _filter_df['fine_tune_dataset'].map(mapping).fillna('fine_tuned')\n",
    "    # levene\n",
    "    grouped_data = [group[dependent_var].values for name, group in _filter_df.groupby(independent_var)]\n",
    "    grouped_data = [group for group in grouped_data if len(group) > 1 and len(set(group)) > 1]  \n",
    "    # filter out groups with only one observation and groups with no variance\n",
    "    stat, pval = levene(*grouped_data, center='mean')\n",
    "    print(f\"Levene’s Test: Statistic = {stat:.4f}, p-value = {pval:.4g}\")\n",
    "    if pval < 0.05:\n",
    "        print(\"Welch\")\n",
    "        assert independent_var is not None and dependent_var is not None\n",
    "        if len(set(_filter_df[independent_var])) < 2:\n",
    "            print(f\"Only one level of {independent_var} found, returning empty DataFrame.\")\n",
    "            return pd.DataFrame(columns=['F', 'PR(>F)', 'sum_sq', 'df', 'mean_sq', 'eta_sq'])\n",
    "        welch_results = welch_anova(dv=dependent_var, between=independent_var, data=_filter_df)\n",
    "        return welch_results\n",
    "    formula=f\"{dependent_var} ~ C({independent_var})\"\n",
    "    _model = ols(formula, data=_filter_df).fit()\n",
    "    anova_table = sm.stats.anova_lm(_model, typ=2)\n",
    "    anova_table['eta_sq'] = anova_table['sum_sq'] / anova_table['sum_sq'].sum()\n",
    "    return anova_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d469c-6b91-4493-ae72-fd8445546d05",
   "metadata": {},
   "source": [
    "## Fine-tuning data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a10df3f-fa80-45fb-9bdb-42c97e95d799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3175\n",
      "2693\n",
      "{'Base', 'Newsarticles', 'Newsroom', 'Canadian-QA', 'OpenR1', 'Imdb', 'Pol-Convo', 'FineTome', 'Scisumm'}\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://docs.google.com/spreadsheets/d/14dHuq-Z52B-RYvYX0IDFgC9ISXDDr9ID/edit?gid=801390513#gid=801390513\"\n",
    "url = \"https://docs.google.com/spreadsheets/d/1L6WA2vUNvY3B7ClDqdYxCKmqTocDbbOz/edit?gid=126664231#gid=126664231\"\n",
    "df = read_gsheet(url=url)\n",
    "print(len(df))\n",
    "df = df.drop_duplicates()\n",
    "df = df[df.model != \"Phi\"]  # filter out Phi\n",
    "df['prompt'] = df['prompt'].astype(str)\n",
    "print(len(df))\n",
    "print(set(df['fine_tune_dataset']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e147e1-97ba-4b4e-93dd-78f2551f1e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falcon 633\n",
      "gemma 720\n",
      "Mistral 627\n",
      "Llama3 713\n"
     ]
    }
   ],
   "source": [
    "## fine tuning data analysis\n",
    "\n",
    "model_split_df = {}\n",
    "\n",
    "output_x = \"Social Libertarian/Authoritarian\"\n",
    "output_y = \"Economic Left/Right\"\n",
    "\n",
    "for model in set(df['model']):\n",
    "    _df = df[(df['model']== model)]\n",
    "    _df.rename(columns={output_x: \"output_x\", output_y: \"output_y\"}, inplace=True)\n",
    "    print(model, len(_df))\n",
    "    model_split_df[model] = _df\n",
    "dependent_vars = [\"output_x\", \"output_y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14cbad3",
   "metadata": {},
   "source": [
    "### indepent t-test\n",
    "\n",
    "determine if we have a difference between fine-tuned and base versions of PCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a48c4c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "(np.float64(-6.127505279754074), np.float64(1.055762172068916e-08))\n",
      "-------------------- Llama3 --------------------\n",
      "(np.float64(5.082108758340775), np.float64(1.1090455663368004e-06))\n",
      "-------------------- Falcon --------------------\n",
      "(np.float64(8.371913648092294), np.float64(2.9543018299527145e-15))\n",
      "-------------------- Mistral --------------------\n",
      "(np.float64(-5.235095992765232), np.float64(6.911225653954734e-07))\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "(np.float64(5.966800986687974), np.float64(2.0666166496433783e-08))\n",
      "-------------------- Llama3 --------------------\n",
      "(np.float64(-9.474745646468088), np.float64(2.0860475515015573e-17))\n",
      "-------------------- Falcon --------------------\n",
      "(np.float64(-0.5598663913560933), np.float64(0.57653193374933))\n",
      "-------------------- Mistral --------------------\n",
      "(np.float64(-22.67638706620761), np.float64(1.4972304988349182e-53))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "models = [\"gemma\", \"Llama3\", \"Falcon\", \"Mistral\"]\n",
    "def t_test(_df: pd.DataFrame, _dependent_var: str):\n",
    "    _df['is_finetuned'] = _df['fine_tune_dataset'].apply(lambda x: 'Base' not in x)\n",
    "    base_dep_var = _df[_df['is_finetuned'] == False][_dependent_var]\n",
    "    finetuned_dep_var = _df[_df['is_finetuned'] == True][_dependent_var]\n",
    "    t_stat, p_value = ttest_ind(base_dep_var, finetuned_dep_var, equal_var=False)\n",
    "    return (t_stat, p_value)    \n",
    "\n",
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\"*20+f\" {dependent_var} \"+\"=:\"*20)\n",
    "    for model in models:\n",
    "        print(\"-\"*20+f\" {model} \"+\"-\"*20)\n",
    "        print(t_test(_df=model_split_df[model], _dependent_var = dependent_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e13a34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text written\n"
     ]
    }
   ],
   "source": [
    "## code to convert it to csv format\n",
    "import csv\n",
    "import re\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
    "-------------------- gemma --------------------\n",
    "(np.float64(-6.127505279754074), np.float64(1.055762172068916e-08))\n",
    "-------------------- Llama3 --------------------\n",
    "(np.float64(5.082108758340775), np.float64(1.1090455663368004e-06))\n",
    "-------------------- Falcon --------------------\n",
    "(np.float64(8.371913648092294), np.float64(2.9543018299527145e-15))\n",
    "-------------------- Mistral --------------------\n",
    "(np.float64(-5.235095992765232), np.float64(6.911225653954734e-07))\n",
    "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
    "-------------------- gemma --------------------\n",
    "(np.float64(5.966800986687974), np.float64(2.0666166496433783e-08))\n",
    "-------------------- Llama3 --------------------\n",
    "(np.float64(-9.474745646468088), np.float64(2.0860475515015573e-17))\n",
    "-------------------- Falcon --------------------\n",
    "(np.float64(-0.5598663913560933), np.float64(0.57653193374933))\n",
    "-------------------- Mistral --------------------\n",
    "(np.float64(-22.67638706620761), np.float64(1.4972304988349182e-53))\n",
    "\"\"\"\n",
    "\n",
    "# Extract results\n",
    "def extract_results(section_text):\n",
    "    pattern = r\"-{5,}\\s*(\\w+)\\s*-{5,}.*?\\(np\\.float64\\(([-+eE\\d\\.]+)\\), np\\.float64\\(([-+eE\\d\\.]+)\\)\\)\"\n",
    "    return {x[0]: (x[1], x[2]) for x in re.findall(pattern, section_text, re.DOTALL)}\n",
    "\n",
    "# Split sections\n",
    "output_x_text = text.split(\"output_x =\")[-1].split(\"output_y =\")[0]\n",
    "output_y_text = text.split(\"output_y =\")[-1]\n",
    "\n",
    "x_results = extract_results(output_x_text)\n",
    "y_results = extract_results(output_y_text)\n",
    "\n",
    "models = [\"gemma\", \"Llama3\", \"Falcon\", \"Mistral\"]\n",
    "rows = []\n",
    "for model in models:\n",
    "    x_stat, x_p = x_results.get(model, (\"\", \"\"))\n",
    "    y_stat, y_p = y_results.get(model, (\"\", \"\"))\n",
    "    rows.append([model, \"{:.2e}\".format(float(x_stat)), \"{:.2e}\".format(float(x_p)), \n",
    "                 \"{:.2e}\".format(float(y_stat)), \"{:.2e}\".format(float(y_p))])\n",
    "\n",
    "# Write CSV\n",
    "with open(\"t_stats.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"model\", \"t-stat-x\", \"p-value\", \"t-stat-y\", \"p-value\"])\n",
    "    writer.writerows(rows)\n",
    "print(\"text written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca7b984-e0b7-477b-b3e3-0b9ad9f4b584",
   "metadata": {},
   "source": [
    "### multi way anova to understand the joint effect of prompts and fine-tune dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddb9277f-c4c5-418f-a4d6-8a9ba7f62e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "Levene’s Test: Statistic = 8.4102, p-value = 1.513e-21\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   700.0  8.444127e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   700.0  1.387190e+06   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   700.0  8.575971e+05   \n",
      "\n",
      "                            Sum Sq.res    F value        Pr(>F)  \n",
      "prompt                    2.259571e+07  29.065929  4.154417e-43  \n",
      "fine_tune_dataset         2.964537e+07  32.754960  1.550529e-08  \n",
      "prompt:fine_tune_dataset  3.016229e+07   2.211437  1.970095e-02  \n",
      "-------------------- Llama3 --------------------\n",
      "Levene’s Test: Statistic = 3.5789, p-value = 4.779e-07\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   693.0  1.665446e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   693.0  1.139668e+06   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   693.0  3.695426e+05   \n",
      "\n",
      "                            Sum Sq.res    F value        Pr(>F)  \n",
      "prompt                    2.842045e+07   4.512221  8.745441e-06  \n",
      "fine_tune_dataset         2.894055e+07  27.290088  2.318861e-07  \n",
      "prompt:fine_tune_dataset  2.962474e+07   0.960507  4.716849e-01  \n",
      "-------------------- Falcon --------------------\n",
      "Levene’s Test: Statistic = 16.8733, p-value = 1.57e-44\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   613.0  2.491218e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   613.0  6.257565e+05   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   613.0  1.482095e+05   \n",
      "\n",
      "                            Sum Sq.res    F value        Pr(>F)  \n",
      "prompt                    1.844981e+07   9.196825  3.888562e-13  \n",
      "fine_tune_dataset         2.022138e+07  18.969461  1.556795e-05  \n",
      "prompt:fine_tune_dataset  2.082047e+07   0.484845  8.851998e-01  \n",
      "-------------------- Mistral --------------------\n",
      "Levene’s Test: Statistic = 11.5625, p-value = 3.207e-30\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   607.0  1.143454e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   607.0  4.401117e+05   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   607.0  9.901578e+05   \n",
      "\n",
      "                            Sum Sq.res    F value    Pr(>F)  \n",
      "prompt                    1.938750e+07   3.977801  0.000060  \n",
      "fine_tune_dataset         2.008808e+07  13.298823  0.000288  \n",
      "prompt:fine_tune_dataset  1.952883e+07   3.419593  0.000407  \n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "Levene’s Test: Statistic = 6.5959, p-value = 4.651e-16\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   700.0  6.715908e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   700.0  1.840088e+06   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   700.0  1.726181e+06   \n",
      "\n",
      "                            Sum Sq.res    F value        Pr(>F)  \n",
      "prompt                    2.429742e+07  21.498102  2.771317e-32  \n",
      "fine_tune_dataset         2.921293e+07  44.092181  6.287845e-11  \n",
      "prompt:fine_tune_dataset  2.935353e+07   4.573845  6.994484e-06  \n",
      "-------------------- Llama3 --------------------\n",
      "Levene’s Test: Statistic = 4.3555, p-value = 2.634e-09\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   693.0  1.791252e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   693.0  1.800514e+06   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   693.0  7.204748e+05   \n",
      "\n",
      "                            Sum Sq.res    F value        Pr(>F)  \n",
      "prompt                    2.828995e+07   4.875456  2.386184e-06  \n",
      "fine_tune_dataset         2.835922e+07  43.998262  6.622597e-11  \n",
      "prompt:fine_tune_dataset  2.938120e+07   1.888165  5.074256e-02  \n",
      "-------------------- Falcon --------------------\n",
      "Levene’s Test: Statistic = 3.3552, p-value = 2.253e-06\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   613.0  2.293624e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   613.0  7.858100e+02   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   613.0  3.444248e+05   \n",
      "\n",
      "                            Sum Sq.res   F value        Pr(>F)  \n",
      "prompt                    1.881984e+07  8.300884  1.017352e-11  \n",
      "fine_tune_dataset         2.108149e+07  0.022849  8.798988e-01  \n",
      "prompt:fine_tune_dataset  2.072867e+07  1.131725  3.377401e-01  \n",
      "-------------------- Mistral --------------------\n",
      "Levene’s Test: Statistic = 6.7392, p-value = 2.882e-16\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   607.0  2.924756e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   607.0  5.470815e+06   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   607.0  8.455530e+05   \n",
      "\n",
      "                            Sum Sq.res     F value        Pr(>F)  \n",
      "prompt                    1.758870e+07   11.215069  2.675569e-16  \n",
      "fine_tune_dataset         1.500849e+07  221.260351  6.745058e-43  \n",
      "prompt:fine_tune_dataset  1.961297e+07    2.907660  2.229715e-03  \n"
     ]
    }
   ],
   "source": [
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\"*20+f\" {dependent_var} \"+\"=:\"*20)\n",
    "    for model in models:\n",
    "        print(\"-\"*20+f\" {model} \"+\"-\"*20)\n",
    "        print(multi_way_anova(_filter_df=model_split_df[model], independent_vars= [\"prompt\", \"fine_tune_dataset\"], dependent_var = dependent_var, collapse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "795266b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output written\n"
     ]
    }
   ],
   "source": [
    "## convert the results to csv format\n",
    "output_x_text = \"\"\"\n",
    "-------------------- gemma --------------------\n",
    "Levene’s Test: Statistic = 8.4102, p-value = 1.513e-21\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   700.0  8.444127e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   700.0  1.387190e+06   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   700.0  8.575971e+05   \n",
    "\n",
    "                            Sum Sq.res    F value        Pr(>F)  \n",
    "prompt                    2.259571e+07  29.065929  4.154417e-43  \n",
    "fine_tune_dataset         2.964537e+07  32.754960  1.550529e-08  \n",
    "prompt:fine_tune_dataset  3.016229e+07   2.211437  1.970095e-02  \n",
    "-------------------- Llama3 --------------------\n",
    "Levene’s Test: Statistic = 3.5789, p-value = 4.779e-07\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   693.0  1.665446e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   693.0  1.139668e+06   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   693.0  3.695426e+05   \n",
    "\n",
    "                            Sum Sq.res    F value        Pr(>F)  \n",
    "prompt                    2.842045e+07   4.512221  8.745441e-06  \n",
    "fine_tune_dataset         2.894055e+07  27.290088  2.318861e-07  \n",
    "prompt:fine_tune_dataset  2.962474e+07   0.960507  4.716849e-01  \n",
    "-------------------- Falcon --------------------\n",
    "Levene’s Test: Statistic = 16.8733, p-value = 1.57e-44\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   613.0  2.491218e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   613.0  6.257565e+05   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   613.0  1.482095e+05   \n",
    "\n",
    "                            Sum Sq.res    F value        Pr(>F)  \n",
    "prompt                    1.844981e+07   9.196825  3.888562e-13  \n",
    "fine_tune_dataset         2.022138e+07  18.969461  1.556795e-05  \n",
    "prompt:fine_tune_dataset  2.082047e+07   0.484845  8.851998e-01  \n",
    "-------------------- Mistral --------------------\n",
    "Levene’s Test: Statistic = 11.5625, p-value = 3.207e-30\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   607.0  1.143454e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   607.0  4.401117e+05   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   607.0  9.901578e+05   \n",
    "\n",
    "                            Sum Sq.res    F value    Pr(>F)  \n",
    "prompt                    1.938750e+07   3.977801  0.000060  \n",
    "fine_tune_dataset         2.008808e+07  13.298823  0.000288  \n",
    "prompt:fine_tune_dataset  1.952883e+07   3.419593  0.000407  \n",
    "\"\"\"\n",
    "output_y_text = \"\"\"\n",
    "evene’s Test: Statistic = 6.5959, p-value = 4.651e-16\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   700.0  6.715908e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   700.0  1.840088e+06   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   700.0  1.726181e+06   \n",
    "\n",
    "                            Sum Sq.res    F value        Pr(>F)  \n",
    "prompt                    2.429742e+07  21.498102  2.771317e-32  \n",
    "fine_tune_dataset         2.921293e+07  44.092181  6.287845e-11  \n",
    "prompt:fine_tune_dataset  2.935353e+07   4.573845  6.994484e-06  \n",
    "-------------------- Llama3 --------------------\n",
    "Levene’s Test: Statistic = 4.3555, p-value = 2.634e-09\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   693.0  1.791252e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   693.0  1.800514e+06   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   693.0  7.204748e+05   \n",
    "\n",
    "                            Sum Sq.res    F value        Pr(>F)  \n",
    "prompt                    2.828995e+07   4.875456  2.386184e-06  \n",
    "fine_tune_dataset         2.835922e+07  43.998262  6.622597e-11  \n",
    "prompt:fine_tune_dataset  2.938120e+07   1.888165  5.074256e-02  \n",
    "-------------------- Falcon --------------------\n",
    "Levene’s Test: Statistic = 3.3552, p-value = 2.253e-06\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   613.0  2.293624e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   613.0  7.858100e+02   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   613.0  3.444248e+05   \n",
    "\n",
    "                            Sum Sq.res   F value        Pr(>F)  \n",
    "prompt                    1.881984e+07  8.300884  1.017352e-11  \n",
    "fine_tune_dataset         2.108149e+07  0.022849  8.798988e-01  \n",
    "prompt:fine_tune_dataset  2.072867e+07  1.131725  3.377401e-01  \n",
    "-------------------- Mistral --------------------\n",
    "Levene’s Test: Statistic = 6.7392, p-value = 2.882e-16\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   607.0  2.924756e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   607.0  5.470815e+06   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   607.0  8.455530e+05   \n",
    "\n",
    "                            Sum Sq.res     F value        Pr(>F)  \n",
    "prompt                    1.758870e+07   11.215069  2.675569e-16  \n",
    "fine_tune_dataset         1.500849e+07  221.260351  6.745058e-43  \n",
    "prompt:fine_tune_dataset  1.961297e+07    2.907660  2.229715e-03\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def return_dependent_var_df(text, x_y=\"x\"):\n",
    "    blocks = re.split(r'-{10,} (.+?) -{10,}', text)[1:]\n",
    "    \n",
    "    # Prepare CSV structure\n",
    "    results = []\n",
    "    \n",
    "    for i in range(0, len(blocks), 2):\n",
    "        model = blocks[i].strip()\n",
    "        content = blocks[i + 1].strip()\n",
    "    \n",
    "        # Find lines containing the ANOVA results\n",
    "        lines = content.strip().split('\\n')\n",
    "        anova_lines = [\n",
    "            line.strip()\n",
    "            for line in lines\n",
    "            if line.strip().startswith(\"prompt\") or\n",
    "               line.strip().startswith(\"fine_tune_dataset\") or\n",
    "               line.strip().startswith(\"prompt:fine_tune_dataset\")\n",
    "        ]\n",
    "    \n",
    "        # Dictionary to hold the output row\n",
    "        row = {\"model\": model}\n",
    "    \n",
    "        for line in anova_lines:\n",
    "            parts = re.split(r'\\s{2,}', line.strip())\n",
    "            if len(parts) < 3:\n",
    "                continue  # Not enough fields\n",
    "    \n",
    "            term = parts[0]\n",
    "            f_value = parts[-2]\n",
    "            p_value = parts[-1]\n",
    "    \n",
    "            if term == \"prompt\":\n",
    "                row[f\"output_{x_y}-prompt-f-score\"] = f\"{float(f_value):.2e}\"\n",
    "                row[f\"output_{x_y}-prompt-p-value\"] = f\"{float(p_value):.2e}\"\n",
    "            elif term == \"fine_tune_dataset\":\n",
    "                row[f\"output_{x_y}-finetune-f-score\"] = f\"{float(f_value):.2e}\"\n",
    "                row[f\"output_{x_y}-finetune-p-value\"] = f\"{float(p_value):.2e}\"\n",
    "            elif term == \"prompt:fine_tune_dataset\":\n",
    "                row[f\"output_{x_y}-prompt-finetune-interaction-f-score\"] = f\"{float(f_value):.2e}\"\n",
    "                row[f\"output_{x_y}-prompt-finetune-interaction-p-value\"] = f\"{float(p_value):.2e}\"\n",
    "        results.append(row)\n",
    "    \n",
    "    return pd.DataFrame(results, columns=[\"model\", f\"output_{x_y}-prompt-f-score\",\n",
    "                                          f\"output_{x_y}-prompt-p-value\",\n",
    "                                         f\"output_{x_y}-finetune-f-score\",\n",
    "                                         f\"output_{x_y}-finetune-p-value\",\n",
    "                                         f\"output_{x_y}-prompt-finetune-interaction-f-score\",\n",
    "                                         f\"output_{x_y}-prompt-finetune-interaction-p-value\"])\n",
    " \n",
    "df_x = return_dependent_var_df(output_x_text)\n",
    "df_y = return_dependent_var_df(output_y_text, x_y=\"y\")\n",
    "stacked = pd.concat([df_x, df_y], axis=1)\n",
    "stacked.to_csv(\"multi_way_anova_results.csv\", index=False)\n",
    "print(f\"output written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4eefaa-de0f-4c5c-8a76-478d8fd23adb",
   "metadata": {},
   "source": [
    "### Does the type of fine-tuning dataset make a difference?\n",
    "\n",
    "Check if the type of the fine-tuning dataset makes a difference. We need to re-download the data because we have converted all fine-tuning datasets to \"fine_tuned\" in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f1e62f-9964-4c0c-8f62-28e7e4db695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2693\n",
      "Falcon 633\n",
      "gemma 720\n",
      "Mistral 627\n",
      "Llama3 713\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      " group1 group2 meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------\n",
      "control target   1.1544   0.0 0.9374 1.3714   True\n",
      "--------------------------------------------------\n",
      "-------------------- Llama3 --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      " group1 group2 meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------\n",
      "control target  -0.5978   0.0 -0.8094 -0.3862   True\n",
      "----------------------------------------------------\n",
      "-------------------- Falcon --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      " group1 group2 meandiff p-adj   lower  upper  reject\n",
      "----------------------------------------------------\n",
      "control target  -0.1053 0.2342 -0.2789 0.0684  False\n",
      "----------------------------------------------------\n",
      "-------------------- Mistral --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      " group1 group2 meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------\n",
      "control target  -1.0759   0.0 -1.2796 -0.8722   True\n",
      "----------------------------------------------------\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      " group1 group2 meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------\n",
      "control target   -1.019   0.0 -1.2485 -0.7895   True\n",
      "----------------------------------------------------\n",
      "-------------------- Llama3 --------------------\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      " group1 group2 meandiff p-adj   lower   upper  reject\n",
      "-----------------------------------------------------\n",
      "control target  -0.5829 0.0001 -0.8804 -0.2855   True\n",
      "-----------------------------------------------------\n",
      "-------------------- Falcon --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      " group1 group2 meandiff p-adj   lower  upper  reject\n",
      "----------------------------------------------------\n",
      "control target  -0.1049 0.3207 -0.3123 0.1024  False\n",
      "----------------------------------------------------\n",
      "-------------------- Mistral --------------------\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      " group1 group2 meandiff p-adj   lower   upper  reject\n",
      "-----------------------------------------------------\n",
      "control target  -0.2846 0.0465 -0.5646 -0.0045   True\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://docs.google.com/spreadsheets/d/14dHuq-Z52B-RYvYX0IDFgC9ISXDDr9ID/edit?gid=801390513#gid=801390513\"\n",
    "url = \"https://docs.google.com/spreadsheets/d/1L6WA2vUNvY3B7ClDqdYxCKmqTocDbbOz/edit?gid=126664231#gid=126664231\"\n",
    "df = read_gsheet(url=url)\n",
    "df = df.drop_duplicates()\n",
    "df = df[df.model != \"Phi\"]  # filter out Phi\n",
    "print(len(df))\n",
    "df['prompt'] = df['prompt'].astype(str)\n",
    "\n",
    "\n",
    "model_split_df = {}\n",
    "\n",
    "output_x = \"Social Libertarian/Authoritarian\"\n",
    "output_y = \"Economic Left/Right\"\n",
    "\n",
    "for model in set(df['model']):\n",
    "    _df = df[(df['model']== model)]\n",
    "    _df.rename(columns={output_x: \"output_x\", output_y: \"output_y\"}, inplace=True)\n",
    "    print(model, len(_df))\n",
    "    model_split_df[model] = _df\n",
    "    \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "dataset_category = {\"target\": {'Canadian-QA', 'Newsarticles', 'Newsroom', 'Pol-Convo'}, \"control\": {\"Imdb\", \"OpenR1\", \"Scisumm\", \"FineTome\"}}\n",
    "# we will test the fuck all \n",
    "def tukey_test(_df, _dependent_var='output_x'):\n",
    "    _df = _df[_df['fine_tune_dataset'] != 'Base']\n",
    "    #print(len(_df), list(_df), set(_df['fine_tune_dataset']))\n",
    "    _df['dataset_group'] = _df['fine_tune_dataset'].apply(lambda x: 'target' if x in dataset_category[\"target\"] else \"control\")\n",
    "    tukey = pairwise_tukeyhsd(endog=_df[_dependent_var],\n",
    "                              groups=_df[\"dataset_group\"],\n",
    "                              alpha=0.05)\n",
    "    return tukey\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def t_test(_df, _dependent_var='output_x'):\n",
    "    _df = _df[_df['fine_tune_dataset'] != 'Base']\n",
    "    _df['dataset_group'] = _df['fine_tune_dataset'].apply(\n",
    "        lambda x: 'target' if x in dataset_category[\"target\"] else \"control\"\n",
    "    )\n",
    "\n",
    "    control_vals = _df[_df['dataset_group'] == 'control'][_dependent_var]\n",
    "    target_vals = _df[_df['dataset_group'] == 'target'][_dependent_var]\n",
    "\n",
    "    t_stat, p_val = ttest_ind(control_vals, target_vals, equal_var=False)\n",
    "    diff = target_vals.mean() - control_vals.mean()\n",
    "\n",
    "    return {\n",
    "        'mean_diff': diff,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_val,\n",
    "        'n_control': len(control_vals),\n",
    "        'n_target': len(target_vals)\n",
    "    }\n",
    "\n",
    "from pprint import pprint\n",
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\"*20+f\" {dependent_var} \"+\"=:\"*20)\n",
    "    for model in models:\n",
    "        print(\"-\"*20+f\" {model} \"+\"-\"*20)\n",
    "        print(tukey_test(_df=model_split_df[model], _dependent_var = dependent_var))\n",
    "        #pprint(t_test(_df=model_split_df[model], _dependent_var = dependent_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "109e42b5-8a0b-471c-97b7-ade132a8e1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "Task: classification\n",
      "        diff      pval\n",
      "0   3.53e-01  4.19e-02\n",
      "1  -2.00e+00  3.53e-14\n",
      "2  -2.35e+00  0.00e+00\n",
      "Task: summarization\n",
      "        diff      pval\n",
      "0  -4.42e-01  1.38e-02\n",
      "1  -1.75e+00  5.41e-13\n",
      "2  -1.31e+00  1.30e-08\n",
      "Task: conversational\n",
      "        diff      pval\n",
      "0  -9.02e-01  1.37e-05\n",
      "1  -2.03e+00  0.00e+00\n",
      "2  -1.13e+00  1.02e-07\n",
      "Task: qa\n",
      "       diff      pval\n",
      "0  1.18e-01  7.92e-01\n",
      "1  2.90e-01  2.10e-01\n",
      "2  1.72e-01  6.31e-01\n",
      "-------------------- Llama3 --------------------\n",
      "Task: classification\n",
      "        diff      pval\n",
      "0   1.39e+00  0.00e+00\n",
      "1  -2.00e-01  4.51e-01\n",
      "2  -1.59e+00  8.22e-15\n",
      "Task: summarization\n",
      "        diff      pval\n",
      "0   9.39e-01  5.77e-13\n",
      "1   4.68e-01  1.26e-03\n",
      "2  -4.71e-01  4.32e-04\n",
      "Task: conversational\n",
      "        diff      pval\n",
      "0  -7.73e-01  1.29e-08\n",
      "1   1.48e+00  0.00e+00\n",
      "2   2.25e+00  0.00e+00\n",
      "Task: qa\n",
      "        diff      pval\n",
      "0  -7.21e-01  1.87e-02\n",
      "1   1.57e+00  2.80e-14\n",
      "2   2.29e+00  2.29e-13\n",
      "-------------------- Falcon --------------------\n",
      "Task: classification\n",
      "        diff      pval\n",
      "0   3.22e-01  7.10e-04\n",
      "1   9.07e-02  4.46e-01\n",
      "2  -2.31e-01  4.56e-02\n",
      "Task: summarization\n",
      "        diff      pval\n",
      "0   3.86e-01  2.16e-04\n",
      "1   2.60e-01  1.27e-01\n",
      "2  -1.26e-01  6.83e-01\n",
      "Task: conversational\n",
      "       diff      pval\n",
      "0  7.52e-01  8.99e-05\n",
      "1  1.80e+00  1.49e-09\n",
      "2  1.04e+00  6.44e-04\n",
      "Task: qa\n",
      "       diff      pval\n",
      "0  3.29e-01  1.83e-02\n",
      "1  8.04e-01  6.43e-11\n",
      "2  4.76e-01  4.54e-03\n",
      "-------------------- Mistral --------------------\n",
      "Task: classification\n",
      "        diff      pval\n",
      "0   6.58e-01  8.92e-07\n",
      "1  -9.29e-01  1.11e-11\n",
      "2  -1.59e+00  2.82e-14\n",
      "Task: summarization\n",
      "        diff      pval\n",
      "0  -2.24e+00  7.77e-15\n",
      "1  -9.37e-01  2.94e-09\n",
      "2   1.30e+00  5.77e-15\n",
      "Task: conversational\n",
      "        diff      pval\n",
      "0  -2.10e+00  6.59e-14\n",
      "1   5.36e-01  1.04e-03\n",
      "2   2.63e+00  5.65e-14\n",
      "Task: qa\n",
      "Only 2 datasets found for task 'qa', returning empty DataFrame.\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "Task: classification\n",
      "        diff      pval\n",
      "0  -5.37e-03  9.99e-01\n",
      "1   1.49e+00  6.84e-13\n",
      "2   1.50e+00  1.88e-12\n",
      "Task: summarization\n",
      "        diff      pval\n",
      "0  -5.90e-01  3.20e-03\n",
      "1   7.93e-01  2.16e-06\n",
      "2   1.38e+00  1.11e-12\n",
      "Task: conversational\n",
      "        diff      pval\n",
      "0   6.92e-01  6.62e-03\n",
      "1   4.30e-01  8.99e-02\n",
      "2  -2.63e-01  5.63e-01\n",
      "Task: qa\n",
      "       diff      pval\n",
      "0  9.14e-01  4.97e-06\n",
      "1  2.37e+00  0.00e+00\n",
      "2  1.46e+00  1.51e-10\n",
      "-------------------- Llama3 --------------------\n",
      "Task: classification\n",
      "        diff      pval\n",
      "0  -4.50e-01  3.70e-02\n",
      "1  -2.43e+00  2.49e-14\n",
      "2  -1.98e+00  0.00e+00\n",
      "Task: summarization\n",
      "        diff      pval\n",
      "0  -5.25e-01  3.25e-03\n",
      "1  -9.64e-01  4.38e-05\n",
      "2  -4.39e-01  1.13e-01\n",
      "Task: conversational\n",
      "        diff      pval\n",
      "0  -2.17e+00  0.00e+00\n",
      "1  -7.15e-02  9.43e-01\n",
      "2   2.10e+00  9.78e-13\n",
      "Task: qa\n",
      "        diff      pval\n",
      "0  -3.20e+00  7.33e-15\n",
      "1  -4.03e-01  1.45e-01\n",
      "2   2.80e+00  1.30e-14\n",
      "-------------------- Falcon --------------------\n",
      "Task: classification\n",
      "        diff      pval\n",
      "0  -1.42e-01  5.90e-01\n",
      "1   2.70e-01  6.91e-02\n",
      "2   4.11e-01  1.12e-02\n",
      "Task: summarization\n",
      "        diff      pval\n",
      "0  -1.09e-02  9.96e-01\n",
      "1  -8.62e-01  2.78e-06\n",
      "2  -8.51e-01  3.23e-06\n",
      "Task: conversational\n",
      "        diff      pval\n",
      "0   4.32e-01  7.96e-02\n",
      "1   6.12e-02  9.75e-01\n",
      "2  -3.70e-01  4.96e-01\n",
      "Task: qa\n",
      "        diff      pval\n",
      "0  -1.12e+00  3.13e-07\n",
      "1   5.81e-01  3.54e-05\n",
      "2   1.70e+00  7.23e-13\n",
      "-------------------- Mistral --------------------\n",
      "Task: classification\n",
      "        diff      pval\n",
      "0  -4.27e-01  1.89e-02\n",
      "1  -3.29e+00  8.80e-14\n",
      "2  -2.87e+00  0.00e+00\n",
      "Task: summarization\n",
      "        diff      pval\n",
      "0  -4.28e+00  0.00e+00\n",
      "1  -2.36e+00  0.00e+00\n",
      "2   1.92e+00  3.52e-14\n",
      "Task: conversational\n",
      "        diff      pval\n",
      "0  -3.93e+00  0.00e+00\n",
      "1  -2.19e+00  2.21e-14\n",
      "2   1.74e+00  7.66e-14\n",
      "Task: qa\n",
      "Only 2 datasets found for task 'qa', returning empty DataFrame.\n",
      "output written\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "dataset_category = {\n",
    "    \"target\": {'Canadian-QA', 'Newsarticles', 'Newsroom', 'Pol-Convo'},\n",
    "    \"control\": {\"Imdb\", \"OpenR1\", \"Scisumm\", \"FineTome\"}\n",
    "}\n",
    "\n",
    "task_dataset_category = {\n",
    "    \"classification\": {\n",
    "        \"target\": 'Newsarticles',\n",
    "        \"control\": \"Imdb\"\n",
    "    },\n",
    "    \"summarization\": {\n",
    "        \"target\": \"Newsroom\",\n",
    "        \"control\": \"Scisumm\"\n",
    "    },\n",
    "    \"conversational\": {\n",
    "        \"target\": \"Pol-Convo\",\n",
    "        \"control\": \"FineTome\"\n",
    "    },\n",
    "    \"qa\": {\n",
    "        \"target\": \"Canadian-QA\",\n",
    "        \"control\": \"OpenR1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def games_howell_test_base(_df, _dependent_var='output_x'):\n",
    "    _df['dataset_group'] = _df['fine_tune_dataset'].apply(\n",
    "        lambda x: 'Base' if x == 'Base' else ('target' if x in dataset_category[\"target\"] else \"control\")\n",
    "    )\n",
    "    assert set(_df['dataset_group']) == {'target', 'control', 'Base'}, \"Dataset groups must be either 'target' or 'control'\"\n",
    "    gh_result = pg.pairwise_gameshowell(dv=_dependent_var, between=\"dataset_group\", data=_df)\n",
    "    return gh_result\n",
    "    \n",
    "def games_howell_test_task_base(_df, task, _dependent_var='output_x'):\n",
    "    task_datasets = set(task_dataset_category[task].values()) | {'Base'}\n",
    "    _df = _df[_df['fine_tune_dataset'].isin(task_datasets)]\n",
    "    if _df['fine_tune_dataset'].nunique() < 3:\n",
    "        print(f\"Only {_df['fine_tune_dataset'].nunique()} datasets found for task '{task}', returning empty DataFrame.\")\n",
    "        return None\n",
    "    _df['dataset_group'] = _df['fine_tune_dataset'].apply(\n",
    "        lambda x: 'Base' if x == 'Base' else ('target' if x in task_dataset_category[task][\"target\"] else \"control\")\n",
    "    )\n",
    "    assert set(_df['dataset_group']) == {'target', 'control', 'Base'}, f\"Dataset groups must be either 'target' or 'control' or 'Base', got {set(_df['dataset_group'])}\"\n",
    "    gh_result = pg.pairwise_gameshowell(dv=_dependent_var, between=\"dataset_group\", data=_df)\n",
    "    return gh_result\n",
    "\n",
    "\n",
    "# dfs = []\n",
    "# for dependent_var in dependent_vars:\n",
    "#     print(\"=:\" * 20 + f\" {dependent_var} \" + \"=:\" * 20)\n",
    "#     for model in models:\n",
    "#         print(\"-\" * 20 + f\" {model} \" + \"-\" * 20)\n",
    "#         result = games_howell_test_base(_df=model_split_df[model], _dependent_var=dependent_var)\n",
    "#         result['model'] = model\n",
    "#         result['dependent_var'] = dependent_var\n",
    "#         result['setup'] = [f\"{x.lower()}-{y.lower()}\" for x,y in zip(result['A'], result['B'])]\n",
    "#         result['diff'] = [f\"{float(x):.2e}\" for x in result['diff']]\n",
    "#         result['pval'] = [f\"{float(x):.2e}\" for x in result['pval']]\n",
    "#         #print(result[['diff', 'pval']])\n",
    "#         dfs.append(result[['model', 'setup', 'diff', 'pval', 'dependent_var']])\n",
    "\n",
    "# pd.concat(dfs, axis=0).to_csv(\"diff_pval_summary_incl_base.csv\", index=False)\n",
    "# print(\"output written\")\n",
    "\n",
    "dfs = []\n",
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\" * 20 + f\" {dependent_var} \" + \"=:\" * 20)\n",
    "    for model in models:\n",
    "        print(\"-\" * 20 + f\" {model} \" + \"-\" * 20)\n",
    "        for task in task_dataset_category.keys():\n",
    "            print(f\"Task: {task}\")\n",
    "            result = games_howell_test_task_base(_df=model_split_df[model], task=task, _dependent_var=dependent_var)\n",
    "            if result is not None:\n",
    "                result['model'] = model\n",
    "                result['task'] = task\n",
    "                result['dependent_var'] = dependent_var\n",
    "                result['setup'] = [f\"{x.lower()}-{y.lower()}\" for x,y in zip(result['A'], result['B'])]\n",
    "                result['diff'] = [f\"{float(x):.2e}\" for x in result['diff']]\n",
    "                result['pval'] = [f\"{float(x):.2e}\" for x in result['pval']]\n",
    "                print(result[['diff', 'pval']])\n",
    "                dfs.append(result[['model', 'task', 'setup', 'diff', 'pval', 'dependent_var']])\n",
    "\n",
    "pd.concat(dfs, axis=0).to_csv(\"diff_pval_summary_task_incl_base.csv\", index=False)\n",
    "print(\"output written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b4668-335a-45d0-b94b-f8ac029e0e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
