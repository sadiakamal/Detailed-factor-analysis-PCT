{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e779bbd2-bfb6-44ca-a2a9-9c21a02b6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import levene\n",
    "from pingouin import welch_anova\n",
    "from rpy2.robjects import pandas2ri, r\n",
    "from rpy2.robjects.packages import importr\n",
    "pandas2ri.activate()\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "ARTool = importr('ARTool')\n",
    "base = importr('base')\n",
    "stats = importr('stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "001353c9-1981-4340-9a9f-bbf009feb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gsheet(url: Optional[str]=None, sheet_id: Optional[str]=None, gid: Optional[str]=None):\n",
    "    if url is not None:\n",
    "        match = re.search(r\"spreadsheets/d/([^/]+)/.*?[?&]gid=(\\d+)\", url)\n",
    "        if match:\n",
    "            sheet_id = match.group(1)\n",
    "            gid = match.group(2)\n",
    "        else:\n",
    "            print(\"can't parse url to get sheet id and gid\")\n",
    "    else:\n",
    "        assert sheet_id is not None and gid is not None, \"Sheet id an gid must be not None when url is not None\"\n",
    "    _url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&id={sheet_id}&gid={gid}\"\n",
    "    return pd.read_csv(_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31fe48a1-cfd5-4050-b311-cb66a24c0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_way_anova(_filter_df: pd.DataFrame, independent_vars: Optional[List[str]] = [\"fine_tune_dataset\"],\n",
    "                    dependent_var: Optional[str] = \"output_x\", collapse: bool=True):\n",
    "    \"\"\"\n",
    "    do multi way anova on the provided dataframe.\n",
    "    :param _filter_df: output from a model\n",
    "    :param dependent_var: predicted variable (column name in the df)\n",
    "    :param independent_vars: contributing factors\n",
    "    :param collapse: instead of saying which dataset it is finetuned on, we will just have 2 values\n",
    "    for this factor -- whether it is finetuned or not\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if collapse:\n",
    "        mapping = {'Base': 'Base'}\n",
    "        _filter_df.loc[:, 'fine_tune_dataset'] = _filter_df['fine_tune_dataset'].map(mapping).fillna('fine_tuned')\n",
    "    # print(f\"df size: {_filter_df.shape}\")\n",
    "    # levene\n",
    "    grouped_data =  _filter_df.groupby(independent_vars)[dependent_var].apply(list)\n",
    "    stat, pval = levene(*grouped_data, center='mean')\n",
    "    print(f\"Levene’s Test: Statistic = {stat:.4f}, p-value = {pval:.4g}\")\n",
    "    if pval < 0.05: # pval must be < 0.05 for us to reject the H_0 at Levenes.\n",
    "        print(\"Robust ANOVA\")\n",
    "        r_df = pandas2ri.py2rpy(_filter_df)\n",
    "        r.assign(\"rdf\", r_df)\n",
    "\n",
    "        for var in independent_vars:\n",
    "            r(f\"rdf${var} <- as.factor(rdf${var})\")\n",
    "        formula_str = f\"{dependent_var} ~ {' * '.join(independent_vars)}\"\n",
    "        r(f'''\n",
    "            library(ARTool)\n",
    "            model <- art({formula_str}, data = rdf)\n",
    "            art_result <- anova(model, type=2)\n",
    "        ''')\n",
    "\n",
    "        art_result = r('art_result')\n",
    "        art_df = pandas2ri.rpy2py(art_result)\n",
    "        return art_df\n",
    "    formula = f\"{dependent_var} ~\" + ' + '.join([f'C({col})' for col in independent_vars])\n",
    "    _model = ols(formula, data=_filter_df).fit()\n",
    "    anova_table = sm.stats.anova_lm(_model, typ=2)\n",
    "    anova_table['eta_sq'] = anova_table['sum_sq'] / anova_table['sum_sq'].sum()\n",
    "    return anova_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23886fa5-bd30-45cf-aa8f-33969b32b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_way_anova(_filter_df: pd.DataFrame, independent_var: Optional[str] = \"fine_tune_dataset\",\n",
    "                  dependent_var: Optional[str] = \"output_x\", collapse: bool=True):\n",
    "    \"\"\"\n",
    "    do one way anova on the provided dataframe.\n",
    "    :param _filter_df: output from a model\n",
    "    :param dependent_var: predicted variable (column name in the df)\n",
    "    :param independent_var: contributing factor\n",
    "    :param collapse: instead of saying which dataset it is finetuned on, we will just have 2 values\n",
    "    for this factor -- whether it is finetuned or not\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #print(f\"df size: {_filter_df.shape}\")\n",
    "    # suppose the independent variable is prompt, then, it is possible that the dependent variable has the same value for all the prompts. \n",
    "    # in that case, we should filter out those rows as the variance will be zero.\n",
    "    grouped_data = _filter_df.groupby(independent_var)\n",
    "    for group_name, group in grouped_data:\n",
    "        if group[dependent_var].nunique() <= 1:\n",
    "            print(f\"Group '{group_name}' has only one unique value for '{dependent_var}', removing it from analysis.\")\n",
    "            _filter_df = _filter_df[_filter_df[independent_var] != group_name]\n",
    "    #print(f\"df size after filtering: {_filter_df.shape}\")\n",
    "    mapping = {'Base': 'Base'}\n",
    "    _filter_df.loc[:, 'fine_tune_dataset'] = _filter_df['fine_tune_dataset'].map(mapping).fillna('fine_tuned')\n",
    "    # levene\n",
    "    grouped_data = [group[dependent_var].values for name, group in _filter_df.groupby(independent_var)]\n",
    "    grouped_data = [group for group in grouped_data if len(group) > 1 and len(set(group)) > 1]  \n",
    "    # filter out groups with only one observation and groups with no variance\n",
    "    stat, pval = levene(*grouped_data, center='mean')\n",
    "    print(f\"Levene’s Test: Statistic = {stat:.4f}, p-value = {pval:.4g}\")\n",
    "    if pval < 0.05:\n",
    "        print(\"Welch\")\n",
    "        assert independent_var is not None and dependent_var is not None\n",
    "        if len(set(_filter_df[independent_var])) < 2:\n",
    "            print(f\"Only one level of {independent_var} found, returning empty DataFrame.\")\n",
    "            return pd.DataFrame(columns=['F', 'PR(>F)', 'sum_sq', 'df', 'mean_sq', 'eta_sq'])\n",
    "        welch_results = welch_anova(dv=dependent_var, between=independent_var, data=_filter_df)\n",
    "        return welch_results\n",
    "    formula=f\"{dependent_var} ~ C({independent_var})\"\n",
    "    _model = ols(formula, data=_filter_df).fit()\n",
    "    anova_table = sm.stats.anova_lm(_model, typ=2)\n",
    "    anova_table['eta_sq'] = anova_table['sum_sq'] / anova_table['sum_sq'].sum()\n",
    "    return anova_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d469c-6b91-4493-ae72-fd8445546d05",
   "metadata": {},
   "source": [
    "## Fine-tuning data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a10df3f-fa80-45fb-9bdb-42c97e95d799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3175\n",
      "2693\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://docs.google.com/spreadsheets/d/14dHuq-Z52B-RYvYX0IDFgC9ISXDDr9ID/edit?gid=801390513#gid=801390513\"\n",
    "url = \"https://docs.google.com/spreadsheets/d/1L6WA2vUNvY3B7ClDqdYxCKmqTocDbbOz/edit?gid=126664231#gid=126664231\"\n",
    "df = read_gsheet(url=url)\n",
    "print(len(df))\n",
    "df = df.drop_duplicates()\n",
    "df = df[df.model != \"Phi\"]  # filter out Phi\n",
    "df['prompt'] = df['prompt'].astype(str)\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e147e1-97ba-4b4e-93dd-78f2551f1e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral 627\n",
      "Falcon 633\n",
      "gemma 720\n",
      "Llama3 713\n"
     ]
    }
   ],
   "source": [
    "## fine tuning data analysis\n",
    "\n",
    "model_split_df = {}\n",
    "\n",
    "output_x = \"Social Libertarian/Authoritarian\"\n",
    "output_y = \"Economic Left/Right\"\n",
    "\n",
    "for model in set(df['model']):\n",
    "    _df = df[(df['model']== model)]\n",
    "    _df.rename(columns={output_x: \"output_x\", output_y: \"output_y\"}, inplace=True)\n",
    "    print(model, len(_df))\n",
    "    model_split_df[model] = _df\n",
    "dependent_vars = [\"output_x\", \"output_y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14cbad3",
   "metadata": {},
   "source": [
    "### indepent t-test\n",
    "\n",
    "determine if we have a difference between fine-tuned and base versions of PCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a48c4c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "(np.float64(-6.127505279754074), np.float64(1.055762172068916e-08))\n",
      "-------------------- Llama3 --------------------\n",
      "(np.float64(5.082108758340775), np.float64(1.1090455663368004e-06))\n",
      "-------------------- Falcon --------------------\n",
      "(np.float64(8.371913648092294), np.float64(2.9543018299527145e-15))\n",
      "-------------------- Mistral --------------------\n",
      "(np.float64(-5.235095992765232), np.float64(6.911225653954734e-07))\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "(np.float64(5.966800986687974), np.float64(2.0666166496433783e-08))\n",
      "-------------------- Llama3 --------------------\n",
      "(np.float64(-9.474745646468088), np.float64(2.0860475515015573e-17))\n",
      "-------------------- Falcon --------------------\n",
      "(np.float64(-0.5598663913560933), np.float64(0.57653193374933))\n",
      "-------------------- Mistral --------------------\n",
      "(np.float64(-22.67638706620761), np.float64(1.4972304988349182e-53))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "models = [\"gemma\", \"Llama3\", \"Falcon\", \"Mistral\"]\n",
    "def t_test(_df: pd.DataFrame, _dependent_var: str):\n",
    "    _df['is_finetuned'] = df['fine_tune_dataset'].apply(lambda x: 'Base' not in x)\n",
    "    base_dep_var = _df[_df['is_finetuned'] == False][_dependent_var]\n",
    "    finetuned_dep_var = _df[_df['is_finetuned'] == True][_dependent_var]\n",
    "    t_stat, p_value = ttest_ind(base_dep_var, finetuned_dep_var, equal_var=False)\n",
    "    return (t_stat, p_value)    \n",
    "\n",
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\"*20+f\" {dependent_var} \"+\"=:\"*20)\n",
    "    for model in models:\n",
    "        print(\"-\"*20+f\" {model} \"+\"-\"*20)\n",
    "        print(t_test(_df=model_split_df[model], _dependent_var = dependent_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e13a34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text written\n"
     ]
    }
   ],
   "source": [
    "## code to convert it to csv format\n",
    "import csv\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "text = \"\"\"\n",
    "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
    "-------------------- gemma --------------------\n",
    "(np.float64(-6.127505279754074), np.float64(1.055762172068916e-08))\n",
    "-------------------- Llama3 --------------------\n",
    "(np.float64(5.082108758340775), np.float64(1.1090455663368004e-06))\n",
    "-------------------- Falcon --------------------\n",
    "(np.float64(8.371913648092294), np.float64(2.9543018299527145e-15))\n",
    "-------------------- Mistral --------------------\n",
    "(np.float64(-5.235095992765232), np.float64(6.911225653954734e-07))\n",
    "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
    "-------------------- gemma --------------------\n",
    "(np.float64(5.966800986687974), np.float64(2.0666166496433783e-08))\n",
    "-------------------- Llama3 --------------------\n",
    "(np.float64(-9.474745646468088), np.float64(2.0860475515015573e-17))\n",
    "-------------------- Falcon --------------------\n",
    "(np.float64(-0.5598663913560933), np.float64(0.57653193374933))\n",
    "-------------------- Mistral --------------------\n",
    "(np.float64(-22.67638706620761), np.float64(1.4972304988349182e-53))\n",
    "\"\"\"\n",
    "\n",
    "# Extract results\n",
    "def extract_results(section_text):\n",
    "    pattern = r\"-{5,}\\s*(\\w+)\\s*-{5,}.*?\\(np\\.float64\\(([-+eE\\d\\.]+)\\), np\\.float64\\(([-+eE\\d\\.]+)\\)\\)\"\n",
    "    return {x[0]: (x[1], x[2]) for x in re.findall(pattern, section_text, re.DOTALL)}\n",
    "\n",
    "# Split sections\n",
    "output_x_text = text.split(\"output_x =\")[-1].split(\"output_y =\")[0]\n",
    "output_y_text = text.split(\"output_y =\")[-1]\n",
    "\n",
    "x_results = extract_results(output_x_text)\n",
    "y_results = extract_results(output_y_text)\n",
    "\n",
    "models = [\"gemma\", \"Llama3\", \"Falcon\", \"Mistral\"]\n",
    "rows = []\n",
    "for model in models:\n",
    "    x_stat, x_p = x_results.get(model, (\"\", \"\"))\n",
    "    y_stat, y_p = y_results.get(model, (\"\", \"\"))\n",
    "    rows.append([model, \"{:.2e}\".format(float(x_stat)), \"{:.2e}\".format(float(x_p)), \n",
    "                 \"{:.2e}\".format(float(y_stat)), \"{:.2e}\".format(float(y_p))])\n",
    "\n",
    "# Write CSV\n",
    "with open(\"t_stats.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"model\", \"t-stat-x\", \"p-value\", \"t-stat-y\", \"p-value\"])\n",
    "    writer.writerows(rows)\n",
    "print(\"text written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca7b984-e0b7-477b-b3e3-0b9ad9f4b584",
   "metadata": {},
   "source": [
    "### multi way anova to understand the joint effect of prompts and fine-tune dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddb9277f-c4c5-418f-a4d6-8a9ba7f62e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "Levene’s Test: Statistic = 8.4102, p-value = 1.513e-21\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   700.0  8.444127e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   700.0  1.387190e+06   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   700.0  8.575971e+05   \n",
      "\n",
      "                            Sum Sq.res    F value        Pr(>F)  \n",
      "prompt                    2.259571e+07  29.065929  4.154417e-43  \n",
      "fine_tune_dataset         2.964537e+07  32.754960  1.550529e-08  \n",
      "prompt:fine_tune_dataset  3.016229e+07   2.211437  1.970095e-02  \n",
      "-------------------- Llama3 --------------------\n",
      "Levene’s Test: Statistic = 3.5789, p-value = 4.779e-07\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   693.0  1.665446e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   693.0  1.139668e+06   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   693.0  3.695426e+05   \n",
      "\n",
      "                            Sum Sq.res    F value        Pr(>F)  \n",
      "prompt                    2.842045e+07   4.512221  8.745441e-06  \n",
      "fine_tune_dataset         2.894055e+07  27.290088  2.318861e-07  \n",
      "prompt:fine_tune_dataset  2.962474e+07   0.960507  4.716849e-01  \n",
      "-------------------- Falcon --------------------\n",
      "Levene’s Test: Statistic = 16.8733, p-value = 1.57e-44\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   613.0  2.491218e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   613.0  6.257565e+05   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   613.0  1.482095e+05   \n",
      "\n",
      "                            Sum Sq.res    F value        Pr(>F)  \n",
      "prompt                    1.844981e+07   9.196825  3.888562e-13  \n",
      "fine_tune_dataset         2.022138e+07  18.969461  1.556795e-05  \n",
      "prompt:fine_tune_dataset  2.082047e+07   0.484845  8.851998e-01  \n",
      "-------------------- Mistral --------------------\n",
      "Levene’s Test: Statistic = 11.5625, p-value = 3.207e-30\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   607.0  1.143454e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   607.0  4.401117e+05   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   607.0  9.901578e+05   \n",
      "\n",
      "                            Sum Sq.res    F value    Pr(>F)  \n",
      "prompt                    1.938750e+07   3.977801  0.000060  \n",
      "fine_tune_dataset         2.008808e+07  13.298823  0.000288  \n",
      "prompt:fine_tune_dataset  1.952883e+07   3.419593  0.000407  \n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "Levene’s Test: Statistic = 6.5959, p-value = 4.651e-16\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   700.0  6.715908e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   700.0  1.840088e+06   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   700.0  1.726181e+06   \n",
      "\n",
      "                            Sum Sq.res    F value        Pr(>F)  \n",
      "prompt                    2.429742e+07  21.498102  2.771317e-32  \n",
      "fine_tune_dataset         2.921293e+07  44.092181  6.287845e-11  \n",
      "prompt:fine_tune_dataset  2.935353e+07   4.573845  6.994484e-06  \n",
      "-------------------- Llama3 --------------------\n",
      "Levene’s Test: Statistic = 4.3555, p-value = 2.634e-09\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   693.0  1.791252e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   693.0  1.800514e+06   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   693.0  7.204748e+05   \n",
      "\n",
      "                            Sum Sq.res    F value        Pr(>F)  \n",
      "prompt                    2.828995e+07   4.875456  2.386184e-06  \n",
      "fine_tune_dataset         2.835922e+07  43.998262  6.622597e-11  \n",
      "prompt:fine_tune_dataset  2.938120e+07   1.888165  5.074256e-02  \n",
      "-------------------- Falcon --------------------\n",
      "Levene’s Test: Statistic = 3.3552, p-value = 2.253e-06\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   613.0  2.293624e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   613.0  7.858100e+02   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   613.0  3.444248e+05   \n",
      "\n",
      "                            Sum Sq.res   F value        Pr(>F)  \n",
      "prompt                    1.881984e+07  8.300884  1.017352e-11  \n",
      "fine_tune_dataset         2.108149e+07  0.022849  8.798988e-01  \n",
      "prompt:fine_tune_dataset  2.072867e+07  1.131725  3.377401e-01  \n",
      "-------------------- Mistral --------------------\n",
      "Levene’s Test: Statistic = 6.7392, p-value = 2.882e-16\n",
      "Robust ANOVA\n",
      "                                              Term   Df  Df.res        Sum Sq  \\\n",
      "prompt                                      prompt  9.0   607.0  2.924756e+06   \n",
      "fine_tune_dataset                fine_tune_dataset  1.0   607.0  5.470815e+06   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   607.0  8.455530e+05   \n",
      "\n",
      "                            Sum Sq.res     F value        Pr(>F)  \n",
      "prompt                    1.758870e+07   11.215069  2.675569e-16  \n",
      "fine_tune_dataset         1.500849e+07  221.260351  6.745058e-43  \n",
      "prompt:fine_tune_dataset  1.961297e+07    2.907660  2.229715e-03  \n"
     ]
    }
   ],
   "source": [
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\"*20+f\" {dependent_var} \"+\"=:\"*20)\n",
    "    for model in models:\n",
    "        print(\"-\"*20+f\" {model} \"+\"-\"*20)\n",
    "        print(multi_way_anova(_filter_df=model_split_df[model], independent_vars= [\"prompt\", \"fine_tune_dataset\"], dependent_var = dependent_var, collapse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "795266b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output written\n"
     ]
    }
   ],
   "source": [
    "## convert the results to csv format\n",
    "text = \"\"\"\n",
    "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
    "-------------------- gemma --------------------\n",
    "df size: (720, 8)\n",
    "Levene’s Test: Statistic = 8.4102, p-value = 1.513e-21\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   700.0  8.444127e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   700.0  1.387190e+06   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   700.0  8.575971e+05   \n",
    "\n",
    "                            Sum Sq.res    F value        Pr(>F)  \n",
    "prompt                    2.259571e+07  29.065929  4.154417e-43  \n",
    "fine_tune_dataset         2.964537e+07  32.754960  1.550529e-08  \n",
    "prompt:fine_tune_dataset  3.016229e+07   2.211437  1.970095e-02  \n",
    "-------------------- Llama3 --------------------\n",
    "df size: (713, 8)\n",
    "Levene’s Test: Statistic = 3.5789, p-value = 4.779e-07\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   693.0  1.665446e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   693.0  1.139668e+06   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   693.0  3.695426e+05   \n",
    "\n",
    "                            Sum Sq.res    F value        Pr(>F)  \n",
    "prompt                    2.842045e+07   4.512221  8.745441e-06  \n",
    "fine_tune_dataset         2.894055e+07  27.290088  2.318861e-07  \n",
    "prompt:fine_tune_dataset  2.962474e+07   0.960507  4.716849e-01  \n",
    "-------------------- Falcon --------------------\n",
    "df size: (633, 8)\n",
    "Levene’s Test: Statistic = 16.8733, p-value = 1.57e-44\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   613.0  2.491218e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   613.0  6.257565e+05   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   613.0  1.482095e+05   \n",
    "\n",
    "                            Sum Sq.res    F value        Pr(>F)  \n",
    "prompt                    1.844981e+07   9.196825  3.888562e-13  \n",
    "fine_tune_dataset         2.022138e+07  18.969461  1.556795e-05  \n",
    "prompt:fine_tune_dataset  2.082047e+07   0.484845  8.851998e-01  \n",
    "-------------------- Mistral --------------------\n",
    "df size: (627, 8)\n",
    "Levene’s Test: Statistic = 11.5625, p-value = 3.207e-30\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   607.0  1.143454e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   607.0  4.401117e+05   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   607.0  9.901578e+05   \n",
    "\n",
    "                            Sum Sq.res    F value    Pr(>F)  \n",
    "prompt                    1.938750e+07   3.977801  0.000060  \n",
    "fine_tune_dataset         2.008808e+07  13.298823  0.000288  \n",
    "prompt:fine_tune_dataset  1.952883e+07   3.419593  0.000407  \n",
    "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
    "-------------------- gemma --------------------\n",
    "df size: (720, 8)\n",
    "Levene’s Test: Statistic = 6.5959, p-value = 4.651e-16\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   700.0  6.715908e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   700.0  1.840088e+06   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   700.0  1.726181e+06   \n",
    "\n",
    "                            Sum Sq.res    F value        Pr(>F)  \n",
    "prompt                    2.429742e+07  21.498102  2.771317e-32  \n",
    "fine_tune_dataset         2.921293e+07  44.092181  6.287845e-11  \n",
    "prompt:fine_tune_dataset  2.935353e+07   4.573845  6.994484e-06  \n",
    "-------------------- Llama3 --------------------\n",
    "df size: (713, 8)\n",
    "Levene’s Test: Statistic = 4.3555, p-value = 2.634e-09\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   693.0  1.791252e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   693.0  1.800514e+06   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   693.0  7.204748e+05   \n",
    "\n",
    "                            Sum Sq.res    F value        Pr(>F)  \n",
    "prompt                    2.828995e+07   4.875456  2.386184e-06  \n",
    "fine_tune_dataset         2.835922e+07  43.998262  6.622597e-11  \n",
    "prompt:fine_tune_dataset  2.938120e+07   1.888165  5.074256e-02  \n",
    "-------------------- Falcon --------------------\n",
    "df size: (633, 8)\n",
    "Levene’s Test: Statistic = 3.3552, p-value = 2.253e-06\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   613.0  2.293624e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   613.0  7.858100e+02   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   613.0  3.444248e+05   \n",
    "\n",
    "                            Sum Sq.res   F value        Pr(>F)  \n",
    "prompt                    1.881984e+07  8.300884  1.017352e-11  \n",
    "fine_tune_dataset         2.108149e+07  0.022849  8.798988e-01  \n",
    "prompt:fine_tune_dataset  2.072867e+07  1.131725  3.377401e-01  \n",
    "-------------------- Mistral --------------------\n",
    "df size: (627, 8)\n",
    "Levene’s Test: Statistic = 6.7392, p-value = 2.882e-16\n",
    "Robust ANOVA\n",
    "                                              Term   Df  Df.res        Sum Sq  \\\n",
    "prompt                                      prompt  9.0   607.0  2.924756e+06   \n",
    "fine_tune_dataset                fine_tune_dataset  1.0   607.0  5.470815e+06   \n",
    "prompt:fine_tune_dataset  prompt:fine_tune_dataset  9.0   607.0  8.455530e+05   \n",
    "\n",
    "                            Sum Sq.res     F value        Pr(>F)  \n",
    "prompt                    1.758870e+07   11.215069  2.675569e-16  \n",
    "fine_tune_dataset         1.500849e+07  221.260351  6.745058e-43  \n",
    "prompt:fine_tune_dataset  1.961297e+07    2.907660  2.229715e-03\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import csv\n",
    "\n",
    "def return_dependent_var_df(text, x_y=\"x\"):\n",
    "    blocks = re.split(r'-{10,} (.+?) -{10,}', text)[1:]\n",
    "    \n",
    "    # Prepare CSV structure\n",
    "    results = []\n",
    "    \n",
    "    for i in range(0, len(blocks), 2):\n",
    "        model = blocks[i].strip()\n",
    "        content = blocks[i + 1].strip()\n",
    "    \n",
    "        # Find lines containing the ANOVA results\n",
    "        lines = content.strip().split('\\n')\n",
    "        anova_lines = [\n",
    "            line.strip()\n",
    "            for line in lines\n",
    "            if line.strip().startswith(\"prompt\") or\n",
    "               line.strip().startswith(\"fine_tune_dataset\") or\n",
    "               line.strip().startswith(\"prompt:fine_tune_dataset\")\n",
    "        ]\n",
    "    \n",
    "        # Dictionary to hold the output row\n",
    "        row = {\"model\": model}\n",
    "    \n",
    "        for line in anova_lines:\n",
    "            parts = re.split(r'\\s{2,}', line.strip())\n",
    "            if len(parts) < 3:\n",
    "                continue  # Not enough fields\n",
    "    \n",
    "            term = parts[0]\n",
    "            f_value = parts[-2]\n",
    "            p_value = parts[-1]\n",
    "    \n",
    "            if term == \"prompt\":\n",
    "                row[f\"output_{x_y}-prompt-f-score\"] = f\"{float(f_value):.2e}\"\n",
    "                row[f\"output_{x_y}-prompt-p-value\"] = f\"{float(p_value):.2e}\"\n",
    "            elif term == \"fine_tune_dataset\":\n",
    "                row[f\"output_{x_y}-finetune-f-score\"] = f\"{float(f_value):.2e}\"\n",
    "                row[f\"output_{x_y}-finetune-p-value\"] = f\"{float(p_value):.2e}\"\n",
    "            elif term == \"prompt:fine_tune_dataset\":\n",
    "                row[f\"output_{x_y}-prompt-finetune-interaction-f-score\"] = f\"{float(f_value):.2e}\"\n",
    "                row[f\"output_{x_y}-prompt-finetune-interaction-p-value\"] = f\"{float(p_value):.2e}\"\n",
    "        results.append(row)\n",
    "    \n",
    "    return pd.DataFrame(results, columns=[\"model\", f\"output_{x_y}-prompt-f-score\",\n",
    "                                          f\"output_{x_y}-prompt-p-value\",\n",
    "                                         f\"output_{x_y}-finetune-f-score\",\n",
    "                                         f\"output_{x_y}-finetune-p-value\",\n",
    "                                         f\"output_{x_y}-prompt-finetune-interaction-f-score\",\n",
    "                                         f\"output_{x_y}-prompt-finetune-interaction-p-value\"])\n",
    " \n",
    "df_x = return_dependent_var_df(output_x_text)\n",
    "df_y = return_dependent_var_df(output_y_text, x_y=\"y\")\n",
    "stacked = pd.concat([df_x, df_y], axis=1)\n",
    "stacked.to_csv(\"multi_way_anova_results.csv\", index=False)\n",
    "print(f\"output written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4eefaa-de0f-4c5c-8a76-478d8fd23adb",
   "metadata": {},
   "source": [
    "### Does the type of fine-tuning dataset make a difference?\n",
    "\n",
    "Check if the type of the fine-tuning dataset makes a difference. We need to re-download the data because we have converted all fine-tuning datasets to \"fine_tuned\" in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4f1e62f-9964-4c0c-8f62-28e7e4db695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2693\n",
      "Mistral 627\n",
      "Falcon 633\n",
      "gemma 720\n",
      "Llama3 713\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "=================================================\n",
      " group1 group2 meandiff p-adj lower  upper reject\n",
      "-------------------------------------------------\n",
      "control target   0.5736   0.0 0.3352 0.812   True\n",
      "-------------------------------------------------\n",
      "-------------------- Llama3 --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      " group1 group2 meandiff p-adj   lower  upper  reject\n",
      "----------------------------------------------------\n",
      "control target  -0.1257 0.2688 -0.3488 0.0974  False\n",
      "----------------------------------------------------\n",
      "-------------------- Falcon --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      " group1 group2 meandiff p-adj  lower  upper reject\n",
      "--------------------------------------------------\n",
      "control target   0.2311 0.0097 0.0562 0.406   True\n",
      "--------------------------------------------------\n",
      "-------------------- Mistral --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      " group1 group2 meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------\n",
      "control target  -0.3738 0.001 -0.5949 -0.1527   True\n",
      "----------------------------------------------------\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      " group1 group2 meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------\n",
      "control target  -1.2644   0.0 -1.4951 -1.0337   True\n",
      "----------------------------------------------------\n",
      "-------------------- Llama3 --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      " group1 group2 meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------\n",
      "control target   0.0171 0.9138 -0.293 0.3272  False\n",
      "---------------------------------------------------\n",
      "-------------------- Falcon --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      " group1 group2 meandiff p-adj   lower  upper  reject\n",
      "----------------------------------------------------\n",
      "control target  -0.0761 0.4766 -0.2861 0.1338  False\n",
      "----------------------------------------------------\n",
      "-------------------- Mistral --------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      " group1 group2 meandiff p-adj   lower  upper  reject\n",
      "----------------------------------------------------\n",
      "control target   0.0514 0.7202 -0.2303 0.3331  False\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://docs.google.com/spreadsheets/d/14dHuq-Z52B-RYvYX0IDFgC9ISXDDr9ID/edit?gid=801390513#gid=801390513\"\n",
    "url = \"https://docs.google.com/spreadsheets/d/1L6WA2vUNvY3B7ClDqdYxCKmqTocDbbOz/edit?gid=126664231#gid=126664231\"\n",
    "df = read_gsheet(url=url)\n",
    "df = df.drop_duplicates()\n",
    "df = df[df.model != \"Phi\"]  # filter out Phi\n",
    "print(len(df))\n",
    "df['prompt'] = df['prompt'].astype(str)\n",
    "\n",
    "\n",
    "model_split_df = {}\n",
    "\n",
    "output_x = \"Social Libertarian/Authoritarian\"\n",
    "output_y = \"Economic Left/Right\"\n",
    "\n",
    "for model in set(df['model']):\n",
    "    _df = df[(df['model']== model)]\n",
    "    _df.rename(columns={output_x: \"output_x\", output_y: \"output_y\"}, inplace=True)\n",
    "    print(model, len(_df))\n",
    "    model_split_df[model] = _df\n",
    "    \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "dataset_category = {\"target\": {'Canadian-QA', 'Newsarticles', 'Newsroom', 'Pol-convo'}, \"control\": {\"Imdb\", \"OpenR1\", \"Scisumm\", \"FineTome\"}}\n",
    "# we will test the fuck all \n",
    "def tukey_test(_df, _dependent_var='output_x'):\n",
    "    _df = _df[_df['fine_tune_dataset'] != 'Base']\n",
    "    #print(len(_df), list(_df), set(_df['fine_tune_dataset']))\n",
    "    _df['dataset_group'] = _df['fine_tune_dataset'].apply(lambda x: 'target' if x in dataset_category[\"target\"] else \"control\")\n",
    "    #model = ols(f'{_dependent_var} ~ C(prompt) + C(fine_tune_dataset) + C(prompt):C(fine_tune_dataset)', data=_df).fit()\n",
    "    #anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    tukey = pairwise_tukeyhsd(endog=_df[_dependent_var],\n",
    "                              groups=_df[\"dataset_group\"],\n",
    "                              alpha=0.05)\n",
    "    return tukey\n",
    "\n",
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\"*20+f\" {dependent_var} \"+\"=:\"*20)\n",
    "    for model in models:\n",
    "        print(\"-\"*20+f\" {model} \"+\"-\"*20)\n",
    "        print(tukey_test(_df=model_split_df[model], _dependent_var = dependent_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "109e42b5-8a0b-471c-97b7-ade132a8e1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "       diff      pval\n",
      "0 -0.573642  0.000008\n",
      "-------------------- Llama3 --------------------\n",
      "       diff      pval\n",
      "0  0.125732  0.244809\n",
      "-------------------- Falcon --------------------\n",
      "       diff      pval\n",
      "0 -0.231071  0.007725\n",
      "-------------------- Mistral --------------------\n",
      "       diff      pval\n",
      "0  0.373778  0.000422\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "-------------------- gemma --------------------\n",
      "       diff  pval\n",
      "0  1.264442   0.0\n",
      "-------------------- Llama3 --------------------\n",
      "       diff      pval\n",
      "0 -0.017108  0.911435\n",
      "-------------------- Falcon --------------------\n",
      "       diff      pval\n",
      "0  0.076148  0.467119\n",
      "-------------------- Mistral --------------------\n",
      "       diff     pval\n",
      "0 -0.051392  0.70409\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "dataset_category = {\n",
    "    \"target\": {'Canadian-QA', 'Newsarticles', 'Newsroom', 'Pol-convo'},\n",
    "    \"control\": {\"Imdb\", \"OpenR1\", \"Scisumm\", \"FineTome\"}\n",
    "}\n",
    "\n",
    "def games_howell_test(_df, _dependent_var='output_x'):\n",
    "    _df = _df[_df['fine_tune_dataset'] != 'Base'].copy()\n",
    "    _df['dataset_group'] = _df['fine_tune_dataset'].apply(lambda x: 'target' if x in dataset_category[\"target\"] else \"control\")\n",
    "    # model = ols(f'{_dependent_var} ~ C(prompt) + C(fine_tune_dataset) + C(prompt):C(fine_tune_dataset)', data=_df).fit()\n",
    "    # anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    gh_result = pg.pairwise_gameshowell(dv=_dependent_var, between=\"dataset_group\", data=_df)\n",
    "    return gh_result\n",
    "\n",
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\" * 20 + f\" {dependent_var} \" + \"=:\" * 20)\n",
    "    for model in models:\n",
    "        print(\"-\" * 20 + f\" {model} \" + \"-\" * 20)\n",
    "        result = games_howell_test(_df=model_split_df[model], _dependent_var=dependent_var)\n",
    "        #print(result)\n",
    "        print(result[['diff', 'pval']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee8816c2-3ecf-4fde-90a7-43713afbc9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output written\n"
     ]
    }
   ],
   "source": [
    "## code to process this output\n",
    "\n",
    "import re\n",
    "import csv\n",
    "\n",
    "text = \"\"\"\n",
    "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
    "-------------------- gemma --------------------\n",
    "       diff      pval\n",
    "0 -0.573642  0.000008\n",
    "-------------------- Llama3 --------------------\n",
    "       diff      pval\n",
    "0  0.125732  0.244809\n",
    "-------------------- Falcon --------------------\n",
    "       diff      pval\n",
    "0 -0.231071  0.007725\n",
    "-------------------- Mistral --------------------\n",
    "       diff      pval\n",
    "0  0.373778  0.000422\n",
    "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
    "-------------------- gemma --------------------\n",
    "       diff  pval\n",
    "0  1.264442   0.0\n",
    "-------------------- Llama3 --------------------\n",
    "       diff      pval\n",
    "0 -0.017108  0.911435\n",
    "-------------------- Falcon --------------------\n",
    "       diff      pval\n",
    "0  0.076148  0.467119\n",
    "-------------------- Mistral --------------------\n",
    "       diff     pval\n",
    "0 -0.051392  0.70409\n",
    "\"\"\"  \n",
    "\n",
    "match = re.search(\n",
    "    r\"=:+ output_x =:+(.*?)=:+ output_y =:+([\\s\\S]*)\", \n",
    "    text, \n",
    "    re.DOTALL\n",
    ")\n",
    "if not match:\n",
    "    raise ValueError(\"Split failed\")\n",
    "\n",
    "output_x_text = match.group(1).strip()\n",
    "output_y_text = match.group(2).strip()\n",
    "\n",
    "# Step 2: Function to extract (diff, pval) per model\n",
    "def extract_model_data(block_text):\n",
    "    model_blocks = re.split(r'-{5,} (.+?) -{5,}', block_text)\n",
    "    data = {}\n",
    "    for i in range(1, len(model_blocks), 2):\n",
    "        model = model_blocks[i].strip()\n",
    "        block = model_blocks[i + 1]\n",
    "        # Search for a line like: 0  -0.573642  0.000008\n",
    "        match = re.search(r'[-+]?\\d*\\.\\d+(?:[eE][-+]?\\d+)?\\s+[-+]?\\d*\\.\\d+(?:[eE][-+]?\\d+)?', block)\n",
    "        if match:\n",
    "            nums = re.findall(r'[-+]?\\d*\\.\\d+(?:[eE][-+]?\\d+)?', match.group())\n",
    "            if len(nums) == 2:\n",
    "                diff = float(nums[0])\n",
    "                pval = float(nums[1])\n",
    "                data[model] = (f\"{diff:.2e}\", f\"{pval:.2e}\")\n",
    "    return data\n",
    "\n",
    "# Step 3: Extract both x and y\n",
    "x_data = extract_model_data(output_x_text)\n",
    "y_data = extract_model_data(output_y_text)\n",
    "\n",
    "# Step 4: Write to CSV\n",
    "with open(\"diff_pval_summary.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"model\", \"diff-x\", \"p-value-x\", \"diff-y\", \"p-value-y\"])\n",
    "    for model in models:\n",
    "        diff_x, pval_x = x_data.get(model, (\"\", \"\"))\n",
    "        diff_y, pval_y = y_data.get(model, (\"\", \"\"))\n",
    "        writer.writerow([model, diff_x, pval_x, diff_y, pval_y])\n",
    "print(\"output written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b4668-335a-45d0-b94b-f8ac029e0e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
