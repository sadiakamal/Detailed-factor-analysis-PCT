{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e779bbd2-bfb6-44ca-a2a9-9c21a02b6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import levene\n",
    "from pingouin import welch_anova\n",
    "from rpy2.robjects import pandas2ri, r\n",
    "from rpy2.robjects.packages import importr\n",
    "pandas2ri.activate()\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "ARTool = importr('ARTool')\n",
    "base = importr('base')\n",
    "stats = importr('stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "001353c9-1981-4340-9a9f-bbf009feb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gsheet(url: Optional[str]=None, sheet_id: Optional[str]=None, gid: Optional[str]=None):\n",
    "    if url is not None:\n",
    "        match = re.search(r\"spreadsheets/d/([^/]+)/.*?[?&]gid=(\\d+)\", url)\n",
    "        if match:\n",
    "            sheet_id = match.group(1)\n",
    "            gid = match.group(2)\n",
    "        else:\n",
    "            print(\"can't parse url to get sheet id and gid\")\n",
    "    else:\n",
    "        assert sheet_id is not None and gid is not None, \"Sheet id an gid must be not None when url is not None\"\n",
    "    _url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&id={sheet_id}&gid={gid}\"\n",
    "    return pd.read_csv(_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31fe48a1-cfd5-4050-b311-cb66a24c0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_way_anova(_filter_df: pd.DataFrame, independent_vars: Optional[List[str]] = [\"fine_tune_dataset\"],\n",
    "                    dependent_var: Optional[str] = \"output_x\", collapse: bool=True):\n",
    "    \"\"\"\n",
    "    do multi way anova on the provided dataframe.\n",
    "    :param _filter_df: output from a model\n",
    "    :param dependent_var: predicted variable (column name in the df)\n",
    "    :param independent_vars: contributing factors\n",
    "    :param collapse: instead of saying which dataset it is finetuned on, we will just have 2 values\n",
    "    for this factor -- whether it is finetuned or not\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if collapse:\n",
    "        mapping = {'Base': 'Base'}\n",
    "        _filter_df.loc[:, 'fine_tune_dataset'] = _filter_df['fine_tune_dataset'].map(mapping).fillna('fine_tuned')\n",
    "    # print(f\"df size: {_filter_df.shape}\")\n",
    "    # levene\n",
    "    grouped_data =  _filter_df.groupby(independent_vars)[dependent_var].apply(list)\n",
    "    stat, pval = levene(*grouped_data, center='mean')\n",
    "    print(f\"Levene’s Test: Statistic = {stat:.4f}, p-value = {pval:.4g}\")\n",
    "    if pval < 0.05: # pval must be < 0.05 for us to reject the H_0 at Levenes.\n",
    "        print(\"Robust ANOVA\")\n",
    "        r_df = pandas2ri.py2rpy(_filter_df)\n",
    "        r.assign(\"rdf\", r_df)\n",
    "\n",
    "        for var in independent_vars:\n",
    "            r(f\"rdf${var} <- as.factor(rdf${var})\")\n",
    "        formula_str = f\"{dependent_var} ~ {' * '.join(independent_vars)}\"\n",
    "        r(f'''\n",
    "            library(ARTool)\n",
    "            model <- art({formula_str}, data = rdf)\n",
    "            art_result <- anova(model, type=2)\n",
    "        ''')\n",
    "\n",
    "        art_result = r('art_result')\n",
    "        art_df = pandas2ri.rpy2py(art_result)\n",
    "        return art_df\n",
    "    formula = f\"{dependent_var} ~\" + ' + '.join([f'C({col})' for col in independent_vars])\n",
    "    _model = ols(formula, data=_filter_df).fit()\n",
    "    anova_table = sm.stats.anova_lm(_model, typ=2)\n",
    "    anova_table['eta_sq'] = anova_table['sum_sq'] / anova_table['sum_sq'].sum()\n",
    "    return anova_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23886fa5-bd30-45cf-aa8f-33969b32b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_way_anova(_filter_df: pd.DataFrame, independent_var: Optional[str] = \"fine_tune_dataset\",\n",
    "                  dependent_var: Optional[str] = \"output_x\", collapse: bool=True):\n",
    "    \"\"\"\n",
    "    do one way anova on the provided dataframe.\n",
    "    :param _filter_df: output from a model\n",
    "    :param dependent_var: predicted variable (column name in the df)\n",
    "    :param independent_var: contributing factor\n",
    "    :param collapse: instead of saying which dataset it is finetuned on, we will just have 2 values\n",
    "    for this factor -- whether it is finetuned or not\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #print(f\"df size: {_filter_df.shape}\")\n",
    "    # suppose the independent variable is prompt, then, it is possible that the dependent variable has the same value for all the prompts. \n",
    "    # in that case, we should filter out those rows as the variance will be zero.\n",
    "    grouped_data = _filter_df.groupby(independent_var)\n",
    "    for group_name, group in grouped_data:\n",
    "        if group[dependent_var].nunique() <= 1:\n",
    "            print(f\"Group '{group_name}' has only one unique value for '{dependent_var}', removing it from analysis.\")\n",
    "            _filter_df = _filter_df[_filter_df[independent_var] != group_name]\n",
    "    #print(f\"df size after filtering: {_filter_df.shape}\")\n",
    "    mapping = {'Base': 'Base'}\n",
    "    _filter_df.loc[:, 'fine_tune_dataset'] = _filter_df['fine_tune_dataset'].map(mapping).fillna('fine_tuned')\n",
    "    # levene\n",
    "    grouped_data = [group[dependent_var].values for name, group in _filter_df.groupby(independent_var)]\n",
    "    grouped_data = [group for group in grouped_data if len(group) > 1 and len(set(group)) > 1]  \n",
    "    # filter out groups with only one observation and groups with no variance\n",
    "    stat, pval = levene(*grouped_data, center='mean')\n",
    "    print(f\"Levene’s Test: Statistic = {stat:.4f}, p-value = {pval:.4g}\")\n",
    "    if pval < 0.05:\n",
    "        print(\"Welch\")\n",
    "        assert independent_var is not None and dependent_var is not None\n",
    "        if len(set(_filter_df[independent_var])) < 2:\n",
    "            print(f\"Only one level of {independent_var} found, returning empty DataFrame.\")\n",
    "            return pd.DataFrame(columns=['F', 'PR(>F)', 'sum_sq', 'df', 'mean_sq', 'eta_sq'])\n",
    "        welch_results = welch_anova(dv=dependent_var, between=independent_var, data=_filter_df)\n",
    "        return welch_results\n",
    "    formula=f\"{dependent_var} ~ C({independent_var})\"\n",
    "    _model = ols(formula, data=_filter_df).fit()\n",
    "    anova_table = sm.stats.anova_lm(_model, typ=2)\n",
    "    anova_table['eta_sq'] = anova_table['sum_sq'] / anova_table['sum_sq'].sum()\n",
    "    return anova_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d469c-6b91-4493-ae72-fd8445546d05",
   "metadata": {},
   "source": [
    "## Fine-tuning data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3e9ac",
   "metadata": {},
   "source": [
    "### generalization studies\n",
    "\n",
    "#### Q1: effect of model size\n",
    "to test the effect of model size, we will ideally compare the base model experiments with \n",
    "- llama-1b-quant and llama-8b-quant\n",
    "- llama-1b-full and llama-8b-full\n",
    "\n",
    "We don't have access to these.\n",
    "\n",
    "Similarly, we can do the fine-tuning experiments with:\n",
    "- llama-1b-quant-peft and llama-8b-quant-peft\n",
    "- llama-1b-full-peft and llama-8b-full-peft\n",
    "\n",
    "We only have llama1b-quant-peft so let's do the experiments with that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a10df3f-fa80-45fb-9bdb-42c97e95d799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966\n",
      "966\n",
      "{'Pol-Convo', 'Scisumm', 'Imdb', 'Newsarticles', 'Canadian-QA', 'Newsroom', 'Base', 'FineTome'}\n"
     ]
    }
   ],
   "source": [
    "url=\"https://docs.google.com/spreadsheets/d/16M6E6upoQi3jjy54-qW3JxasDUs2MOrA/edit?gid=948710219#gid=948710219\"\n",
    "df = read_gsheet(url=url)\n",
    "print(len(df))\n",
    "df = df.drop_duplicates()\n",
    "df = df[df.model != \"Phi\"]  # filter out Phi\n",
    "df['prompt'] = df['prompt'].astype(str)\n",
    "print(len(df))\n",
    "print(set(df['fine_tune_dataset']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61b701e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "model_split_df = {}\n",
    "\n",
    "output_x = \"Social Libertarian/Authoritarian\"\n",
    "output_y = \"Economic Left/Right\"\n",
    "\n",
    "df.rename(columns={output_x: \"output_x\", output_y: \"output_y\"}, inplace=True)\n",
    "\n",
    "llama_1b_base_quant = df[df['type'] == \"base-quant\"]\n",
    "llama_1b_base_full = df[df['type'] == \"base-full\"]\n",
    "print(len(llama_1b_base_full))\n",
    "print(len(llama_1b_base_quant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8cbaab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "==================== tmp ====================\n",
      "Levene’s Test: Statistic = 0.2775, p-value = 0.6\n",
      "             sum_sq    df         F    PR(>F)    eta_sq\n",
      "C(tmp)     0.475200   1.0  0.389078  0.534872  0.005689\n",
      "Residual  83.051887  68.0       NaN       NaN  0.994311\n",
      "==================== top_k ====================\n",
      "Levene’s Test: Statistic = 0.3417, p-value = 0.5608\n",
      "             sum_sq    df        F    PR(>F)    eta_sq\n",
      "C(top_k)   0.156516   1.0  0.12766  0.721977  0.001874\n",
      "Residual  83.370571  68.0      NaN       NaN  0.998126\n",
      "==================== n_beams ====================\n",
      "Levene’s Test: Statistic = 0.1986, p-value = 0.6573\n",
      "               sum_sq    df         F    PR(>F)    eta_sq\n",
      "C(n_beams)   0.001750   1.0  0.001425  0.970001  0.000021\n",
      "Residual    83.525337  68.0       NaN       NaN  0.999979\n",
      "==================== prompt ====================\n",
      "Group '2' has only one unique value for 'output_x', removing it from analysis.\n",
      "Levene’s Test: Statistic = 2.8840, p-value = 0.01237\n",
      "Welch\n",
      "   Source  ddof1      ddof2          F         p-unc       np2\n",
      "0  prompt      7  22.715332  13.503933  9.179571e-07  0.808745\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "==================== tmp ====================\n",
      "Levene’s Test: Statistic = 0.0005, p-value = 0.9825\n",
      "             sum_sq    df         F    PR(>F)    eta_sq\n",
      "C(tmp)     0.770640   1.0  1.048363  0.309513  0.015183\n",
      "Residual  49.986058  68.0       NaN       NaN  0.984817\n",
      "==================== top_k ====================\n",
      "Levene’s Test: Statistic = 0.0223, p-value = 0.8817\n",
      "             sum_sq    df         F    PR(>F)    eta_sq\n",
      "C(top_k)   0.026813   1.0  0.035941  0.850202  0.000528\n",
      "Residual  50.729886  68.0       NaN       NaN  0.999472\n",
      "==================== n_beams ====================\n",
      "Levene’s Test: Statistic = 1.3558, p-value = 0.2483\n",
      "               sum_sq    df        F    PR(>F)    eta_sq\n",
      "C(n_beams)   0.188241   1.0  0.25313  0.616505  0.003709\n",
      "Residual    50.568457  68.0      NaN       NaN  0.996291\n",
      "==================== prompt ====================\n",
      "Group '2' has only one unique value for 'output_y', removing it from analysis.\n",
      "Levene’s Test: Statistic = 1.9524, p-value = 0.079\n",
      "              sum_sq    df        F    PR(>F)    eta_sq\n",
      "C(prompt)  19.846045   7.0  5.52625  0.000079  0.417374\n",
      "Residual   27.703789  54.0      NaN       NaN  0.582626\n"
     ]
    }
   ],
   "source": [
    "gen_factors = [\"tmp\", \"top_k\", \"n_beams\", \"prompt\"]\n",
    "dependent_vars = [\"output_x\", \"output_y\"]\n",
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\"*20+f\" {dependent_var} \"+\"=:\"*20)\n",
    "    for gen_factor in gen_factors:\n",
    "        print(\"=\"*20+f\" {gen_factor} \"+\"=\"*20)\n",
    "        print(one_way_anova(_filter_df=llama_1b_base_full, independent_var = gen_factor,\n",
    "                    dependent_var = dependent_var, collapse=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f75ceee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966\n",
      "966\n",
      "{'Pol-Convo', 'Scisumm', 'Imdb', 'Newsarticles', 'Canadian-QA', 'Newsroom', 'Base', 'FineTome'}\n",
      "Llama1B 471\n"
     ]
    }
   ],
   "source": [
    "url=\"https://docs.google.com/spreadsheets/d/16M6E6upoQi3jjy54-qW3JxasDUs2MOrA/edit?gid=948710219#gid=948710219\"\n",
    "df = read_gsheet(url=url)\n",
    "print(len(df))\n",
    "df = df.drop_duplicates()\n",
    "df = df[df.model != \"Phi\"]  # filter out Phi\n",
    "df['prompt'] = df['prompt'].astype(str)\n",
    "print(len(df))\n",
    "print(set(df['fine_tune_dataset']))\n",
    "\n",
    "model_split_df = {}\n",
    "\n",
    "output_x = \"Social Libertarian/Authoritarian\"\n",
    "output_y = \"Economic Left/Right\"\n",
    "\n",
    "for model in set(df['model']):\n",
    "    #_df = df[(df['model']== model) & (df['type'].isin([\"peft-quant\", \"base-quant\"]))]\n",
    "    _df = df[(df['model']== model) & (df['type'].isin([\"peft\", \"base-full\"]))]\n",
    "    _df.rename(columns={output_x: \"output_x\", output_y: \"output_y\"}, inplace=True)\n",
    "    print(model, len(_df))\n",
    "    model_split_df[model] = _df\n",
    "dependent_vars = [\"output_x\", \"output_y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14cbad3",
   "metadata": {},
   "source": [
    "### indepent t-test\n",
    "\n",
    "determine if we have a difference between fine-tuned and base versions of PCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a48c4c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "(np.float64(-32.74110826453176), np.float64(5.969774780743185e-57))\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "(np.float64(-8.385910965573048), np.float64(5.973144981266671e-13))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def t_test(_df: pd.DataFrame, _dependent_var: str):\n",
    "    #print(set(_df['fine_tune_dataset']))\n",
    "    _df['is_finetuned'] = _df['fine_tune_dataset'].apply(lambda x: 'Base' not in x)\n",
    "    base_dep_var = _df[_df['is_finetuned'] == False][_dependent_var]\n",
    "    finetuned_dep_var = _df[_df['is_finetuned'] == True][_dependent_var]\n",
    "    #print(len(base_dep_var), len(finetuned_dep_var))\n",
    "    t_stat, p_value = ttest_ind(base_dep_var, finetuned_dep_var, equal_var=False)\n",
    "    return (t_stat, p_value)    \n",
    "\n",
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\"*20+f\" {dependent_var} \"+\"=:\"*20)\n",
    "    print(t_test(_df=model_split_df[\"Llama1B\"], _dependent_var = dependent_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca7b984-e0b7-477b-b3e3-0b9ad9f4b584",
   "metadata": {},
   "source": [
    "### multi way anova to understand the joint effect of prompts and fine-tune dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54fc81af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966\n",
      "966\n",
      "{'Pol-Convo', 'Scisumm', 'Imdb', 'Newsarticles', 'Canadian-QA', 'Newsroom', 'Base', 'FineTome'}\n",
      "Llama1B 471\n"
     ]
    }
   ],
   "source": [
    "url=\"https://docs.google.com/spreadsheets/d/16M6E6upoQi3jjy54-qW3JxasDUs2MOrA/edit?gid=948710219#gid=948710219\"\n",
    "df = read_gsheet(url=url)\n",
    "print(len(df))\n",
    "df = df.drop_duplicates()\n",
    "df = df[df.model != \"Phi\"]  # filter out Phi\n",
    "df['prompt'] = df['prompt'].astype(str)\n",
    "print(len(df))\n",
    "print(set(df['fine_tune_dataset']))\n",
    "\n",
    "model_split_df = {}\n",
    "\n",
    "output_x = \"Social Libertarian/Authoritarian\"\n",
    "output_y = \"Economic Left/Right\"\n",
    "\n",
    "for model in set(df['model']):\n",
    "    # _df = df[(df['model']== model) & (df['type'].isin([\"peft-quant\", \"base-quant\"]))]\n",
    "    _df = df[(df['model']== model) & (df['type'].isin([\"peft\", \"base-full\"]))]\n",
    "    _df.rename(columns={output_x: \"output_x\", output_y: \"output_y\"}, inplace=True)\n",
    "    print(model, len(_df))\n",
    "    model_split_df[model] = _df\n",
    "dependent_vars = [\"output_x\", \"output_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddb9277f-c4c5-418f-a4d6-8a9ba7f62e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Note: model has aliased coefficients\n",
      "      sums of squares computed by model comparison\n",
      "\n",
      "R[write to console]: Note: model has aliased coefficients\n",
      "      sums of squares computed by model comparison\n",
      "\n",
      "R[write to console]: Note: model has aliased coefficients\n",
      "      sums of squares computed by model comparison\n",
      "\n",
      "R[write to console]: Note: model has aliased coefficients\n",
      "      sums of squares computed by model comparison\n",
      "\n",
      "R[write to console]: Note: model has aliased coefficients\n",
      "      sums of squares computed by model comparison\n",
      "\n",
      "R[write to console]: Note: model has aliased coefficients\n",
      "      sums of squares computed by model comparison\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471 {'Pol-Convo', 'Scisumm', 'Imdb', 'Newsarticles', 'Canadian-QA', 'Newsroom', 'Base', 'FineTome'}\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "Levene’s Test: Statistic = 4.3453, p-value = 8.22e-21\n",
      "Robust ANOVA\n",
      "                                              Term    Df  Df.res  \\\n",
      "prompt                                      prompt   9.0   402.0   \n",
      "fine_tune_dataset                fine_tune_dataset   7.0   402.0   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  52.0   402.0   \n",
      "\n",
      "                                Sum Sq    Sum Sq.res     F value  \\\n",
      "prompt                    3.459763e+06  4.987889e+06   30.982261   \n",
      "fine_tune_dataset         7.323279e+06  1.224297e+06  343.515838   \n",
      "prompt:fine_tune_dataset  4.555424e+06  3.480247e+06   10.119091   \n",
      "\n",
      "                                 Pr(>F)  \n",
      "prompt                     4.718145e-41  \n",
      "fine_tune_dataset         2.777726e-165  \n",
      "prompt:fine_tune_dataset   7.912064e-47  \n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "Levene’s Test: Statistic = 4.2886, p-value = 1.958e-20\n",
      "Robust ANOVA\n",
      "                                              Term    Df  Df.res  \\\n",
      "prompt                                      prompt   9.0   402.0   \n",
      "fine_tune_dataset                fine_tune_dataset   7.0   402.0   \n",
      "prompt:fine_tune_dataset  prompt:fine_tune_dataset  52.0   402.0   \n",
      "\n",
      "                                Sum Sq    Sum Sq.res    F value        Pr(>F)  \n",
      "prompt                    1.337941e+06  6.962930e+06   8.582787  8.615232e-12  \n",
      "fine_tune_dataset         5.158210e+06  3.365122e+06  88.029099  3.790724e-77  \n",
      "prompt:fine_tune_dataset  3.250825e+06  4.982322e+06   5.044109  1.657995e-21  \n"
     ]
    }
   ],
   "source": [
    "print(len(model_split_df[\"Llama1B\"]), set(model_split_df[\"Llama1B\"]['fine_tune_dataset']))\n",
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\"*20+f\" {dependent_var} \"+\"=:\"*20)\n",
    "    print(multi_way_anova(_filter_df=model_split_df[\"Llama1B\"], independent_vars= [\"prompt\", \"fine_tune_dataset\"], dependent_var = dependent_var, collapse=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4eefaa-de0f-4c5c-8a76-478d8fd23adb",
   "metadata": {},
   "source": [
    "### Does the type of fine-tuning dataset make a difference?\n",
    "\n",
    "Check if the type of the fine-tuning dataset makes a difference. We need to re-download the data because we have converted all fine-tuning datasets to \"fine_tuned\" in the last step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e91b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b4f1e62f-9964-4c0c-8f62-28e7e4db695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966\n",
      "966\n",
      "{'Pol-Convo', 'Scisumm', 'Imdb', 'Newsarticles', 'Canadian-QA', 'Newsroom', 'Base', 'FineTome'}\n",
      "Llama1B 471\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      " group1 group2 meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------\n",
      "control target   1.5478   0.0 1.3414 1.7542   True\n",
      "--------------------------------------------------\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      " group1 group2 meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------\n",
      "control target    0.554   0.0 0.4046 0.7033   True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "url=\"https://docs.google.com/spreadsheets/d/16M6E6upoQi3jjy54-qW3JxasDUs2MOrA/edit?gid=948710219#gid=948710219\"\n",
    "df = read_gsheet(url=url)\n",
    "print(len(df))\n",
    "df = df.drop_duplicates()\n",
    "df = df[df.model != \"Phi\"]  # filter out Phi\n",
    "df['prompt'] = df['prompt'].astype(str)\n",
    "print(len(df))\n",
    "print(set(df['fine_tune_dataset']))\n",
    "\n",
    "model_split_df = {}\n",
    "\n",
    "output_x = \"Social Libertarian/Authoritarian\"\n",
    "output_y = \"Economic Left/Right\"\n",
    "\n",
    "for model in set(df['model']):\n",
    "    #_df = df[(df['model']== model) & (df['type'].isin([\"peft-quant\", \"base-quant\"]))]\n",
    "    _df = df[(df['model']== model) & (df['type'].isin([\"peft\", \"base-full\"]))]\n",
    "    _df.rename(columns={output_x: \"output_x\", output_y: \"output_y\"}, inplace=True)\n",
    "    print(model, len(_df))\n",
    "    model_split_df[model] = _df\n",
    "dependent_vars = [\"output_x\", \"output_y\"]\n",
    "    \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "dataset_category = {\"target\": {'Canadian-QA', 'Newsarticles', 'Newsroom', 'Pol-Convo'}, \"control\": {\"Imdb\", \"OpenR1\", \"Scisumm\", \"FineTome\"}}\n",
    "# we will test the fuck all \n",
    "def tukey_test(_df, _dependent_var='output_x'):\n",
    "    _df = _df[_df['fine_tune_dataset'] != 'Base']\n",
    "    #print(len(_df), list(_df), set(_df['fine_tune_dataset']))\n",
    "    _df['dataset_group'] = _df['fine_tune_dataset'].apply(lambda x: 'target' if x in dataset_category[\"target\"] else \"control\")\n",
    "    tukey = pairwise_tukeyhsd(endog=_df[_dependent_var],\n",
    "                              groups=_df[\"dataset_group\"],\n",
    "                              alpha=0.05)\n",
    "    return tukey\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def t_test(_df, _dependent_var='output_x'):\n",
    "    _df = _df[_df['fine_tune_dataset'] != 'Base']\n",
    "    _df['dataset_group'] = _df['fine_tune_dataset'].apply(\n",
    "        lambda x: 'target' if x in dataset_category[\"target\"] else \"control\"\n",
    "    )\n",
    "\n",
    "    control_vals = _df[_df['dataset_group'] == 'control'][_dependent_var]\n",
    "    target_vals = _df[_df['dataset_group'] == 'target'][_dependent_var]\n",
    "\n",
    "    t_stat, p_val = ttest_ind(control_vals, target_vals, equal_var=False)\n",
    "    diff = target_vals.mean() - control_vals.mean()\n",
    "\n",
    "    return {\n",
    "        'mean_diff': diff,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_val,\n",
    "        'n_control': len(control_vals),\n",
    "        'n_target': len(target_vals)\n",
    "    }\n",
    "\n",
    "from pprint import pprint\n",
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\"*20+f\" {dependent_var} \"+\"=:\"*20)\n",
    "    print(tukey_test(_df=model_split_df[\"Llama1B\"], _dependent_var = dependent_var))\n",
    "        #pprint(t_test(_df=model_split_df[model], _dependent_var = dependent_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "109e42b5-8a0b-471c-97b7-ade132a8e1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_x =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "Task: classification\n",
      "        diff      pval\n",
      "0  -4.11e+00  2.22e-15\n",
      "1  -5.59e+00  1.07e-14\n",
      "2  -1.48e+00  0.00e+00\n",
      "Task: summarization\n",
      "        diff      pval\n",
      "0  -4.31e+00  3.44e-15\n",
      "1  -4.72e+00  3.55e-14\n",
      "2  -4.12e-01  3.12e-01\n",
      "Task: conversational\n",
      "        diff      pval\n",
      "0  -3.32e+00  3.44e-15\n",
      "1  -5.06e+00  0.00e+00\n",
      "2  -1.74e+00  2.12e-14\n",
      "Task: qa\n",
      "Only 2 datasets found for task 'qa', returning empty DataFrame.\n",
      "=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=: output_y =:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:=:\n",
      "Task: classification\n",
      "        diff      pval\n",
      "0  -1.12e+00  0.00e+00\n",
      "1  -1.42e+00  3.22e-14\n",
      "2  -3.05e-01  8.85e-04\n",
      "Task: summarization\n",
      "        diff      pval\n",
      "0  -3.54e-02  9.80e-01\n",
      "1  -1.23e+00  8.38e-13\n",
      "2  -1.19e+00  4.12e-08\n",
      "Task: conversational\n",
      "        diff      pval\n",
      "0  -2.99e-01  1.95e-01\n",
      "1  -1.40e+00  0.00e+00\n",
      "2  -1.10e+00  5.92e-10\n",
      "Task: qa\n",
      "Only 2 datasets found for task 'qa', returning empty DataFrame.\n",
      "output written\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "dataset_category = {\n",
    "    \"target\": {'Canadian-QA', 'Newsarticles', 'Newsroom', 'Pol-Convo'},\n",
    "    \"control\": {\"Imdb\", \"OpenR1\", \"Scisumm\", \"FineTome\"}\n",
    "}\n",
    "\n",
    "task_dataset_category = {\n",
    "    \"classification\": {\n",
    "        \"target\": 'Newsarticles',\n",
    "        \"control\": \"Imdb\"\n",
    "    },\n",
    "    \"summarization\": {\n",
    "        \"target\": \"Newsroom\",\n",
    "        \"control\": \"Scisumm\"\n",
    "    },\n",
    "    \"conversational\": {\n",
    "        \"target\": \"Pol-Convo\",\n",
    "        \"control\": \"FineTome\"\n",
    "    },\n",
    "    \"qa\": {\n",
    "        \"target\": \"Canadian-QA\",\n",
    "        \"control\": \"OpenR1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def games_howell_test_base(_df, _dependent_var='output_x'):\n",
    "    _df['dataset_group'] = _df['fine_tune_dataset'].apply(\n",
    "        lambda x: 'Base' if x == 'Base' else ('target' if x in dataset_category[\"target\"] else \"control\")\n",
    "    )\n",
    "    assert set(_df['dataset_group']) == {'target', 'control', 'Base'}, \"Dataset groups must be either 'target' or 'control'\"\n",
    "    gh_result = pg.pairwise_gameshowell(dv=_dependent_var, between=\"dataset_group\", data=_df)\n",
    "    return gh_result\n",
    "    \n",
    "def games_howell_test_task_base(_df, task, _dependent_var='output_x'):\n",
    "    task_datasets = set(task_dataset_category[task].values()) | {'Base'}\n",
    "    _df = _df[_df['fine_tune_dataset'].isin(task_datasets)]\n",
    "    if _df['fine_tune_dataset'].nunique() < 3:\n",
    "        print(f\"Only {_df['fine_tune_dataset'].nunique()} datasets found for task '{task}', returning empty DataFrame.\")\n",
    "        return None\n",
    "    _df['dataset_group'] = _df['fine_tune_dataset'].apply(\n",
    "        lambda x: 'Base' if x == 'Base' else ('target' if x in task_dataset_category[task][\"target\"] else \"control\")\n",
    "    )\n",
    "    assert set(_df['dataset_group']) == {'target', 'control', 'Base'}, f\"Dataset groups must be either 'target' or 'control' or 'Base', got {set(_df['dataset_group'])}\"\n",
    "    gh_result = pg.pairwise_gameshowell(dv=_dependent_var, between=\"dataset_group\", data=_df)\n",
    "    return gh_result\n",
    "\n",
    "\n",
    "# dfs = []\n",
    "# for dependent_var in dependent_vars:\n",
    "#     print(\"=:\" * 20 + f\" {dependent_var} \" + \"=:\" * 20)\n",
    "#     for model in models:\n",
    "#         print(\"-\" * 20 + f\" {model} \" + \"-\" * 20)\n",
    "#         result = games_howell_test_base(_df=model_split_df[model], _dependent_var=dependent_var)\n",
    "#         result['model'] = model\n",
    "#         result['dependent_var'] = dependent_var\n",
    "#         result['setup'] = [f\"{x.lower()}-{y.lower()}\" for x,y in zip(result['A'], result['B'])]\n",
    "#         result['diff'] = [f\"{float(x):.2e}\" for x in result['diff']]\n",
    "#         result['pval'] = [f\"{float(x):.2e}\" for x in result['pval']]\n",
    "#         #print(result[['diff', 'pval']])\n",
    "#         dfs.append(result[['model', 'setup', 'diff', 'pval', 'dependent_var']])\n",
    "\n",
    "# pd.concat(dfs, axis=0).to_csv(\"diff_pval_summary_incl_base.csv\", index=False)\n",
    "# print(\"output written\")\n",
    "\n",
    "dfs = []\n",
    "for dependent_var in dependent_vars:\n",
    "    print(\"=:\" * 20 + f\" {dependent_var} \" + \"=:\" * 20)\n",
    "    for task in task_dataset_category.keys():\n",
    "        print(f\"Task: {task}\")\n",
    "        result = games_howell_test_task_base(_df=model_split_df[\"Llama1B\"], task=task, _dependent_var=dependent_var)\n",
    "        if result is not None:\n",
    "            result['model'] = \"Llama1B\"\n",
    "            result['task'] = task\n",
    "            result['dependent_var'] = dependent_var\n",
    "            result['setup'] = [f\"{x.lower()}-{y.lower()}\" for x,y in zip(result['A'], result['B'])]\n",
    "            result['diff'] = [f\"{float(x):.2e}\" for x in result['diff']]\n",
    "            result['pval'] = [f\"{float(x):.2e}\" for x in result['pval']]\n",
    "            print(result[['diff', 'pval']])\n",
    "            dfs.append(result[['model', 'task', 'setup', 'diff', 'pval', 'dependent_var']])\n",
    "\n",
    "pd.concat(dfs, axis=0).to_csv(\"diff_pval_summary_task_incl_base_llama1b_full.csv\", index=False)\n",
    "print(\"output written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b4668-335a-45d0-b94b-f8ac029e0e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
